{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34347356",
   "metadata": {},
   "source": [
    "# SIS Health Vector\n",
    "\n",
    "Eignung für das Vorkommen und die saisonale Aktivität der Tigermücke (Aedes albopictus) in Europa\n",
    "\n",
    "Dieses Skript verarbeitet den Datensatz **SIS Health Vector** aus dem Copernics Climate Data Store. Der Datensatz enthält Informationen zu der Eignung der Umweltbedingungen sowie der saisonalen Aktivität der Tigermücke. Der Datensatz wurde im Rahmen des C3S European Health Service entwickelt. Die Informationen sind für unterschiedliche zukünftige Zeiträume und Klimawandelszenarien verfügbar.\n",
    "\n",
    "**Informationen zum Datensatz**: \n",
    "\n",
    "* Source: [SIS Health Vector](https://cds.climate.copernicus.eu/datasets/sis-health-vector?tab=overview)\n",
    "* Author: T. Tewes (Stadt Konstanz) \n",
    "* Notebook-Version: 1.1 (Updated: December 02, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc12136",
   "metadata": {},
   "source": [
    "## 1. Specifying the paths and working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b939873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' ---- Hier die Verzeichnisse angeben ---- '''\n",
    "download_folder = r\".\\data\\sis-health-vector\\download\"\n",
    "working_folder = r\".\\data\\sis-health-vector\\working\"\n",
    "geotiff_folder = r\".\\data\\sis-health-vector\\geotiff\"\n",
    "csv_folder = r\".\\data\\sis-health-vector\\csv\"\n",
    "output_folder = r\".\\data\\sis-health-vector\\output\"\n",
    "''' ----- Ende der Eingaben ---- '''\n",
    "\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "os.makedirs(working_folder, exist_ok=True)\n",
    "os.makedirs(geotiff_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084bec7",
   "metadata": {},
   "source": [
    "## 2. Download and Extract Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59f15a",
   "metadata": {},
   "source": [
    "### 2.1 API Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef08eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "def main():\n",
    "    api_key = \"fdae60fd-35d4-436f-825c-c63fedab94a4\"\n",
    "    api_url = \"https://cds.climate.copernicus.eu/api\"\n",
    "    client = cdsapi.Client(url=api_url, key=api_key)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77ceda",
   "metadata": {},
   "source": [
    "### 2.2 Request Definition and Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6c35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define additional request fields to ensure the request stays within the file size limit.\n",
    "# These coordinates were obtained using the BBox Extractor tool:\n",
    "# https://str-ucture.github.io/bbox-extractor/\n",
    "\n",
    "bbox_wgs84_deutschland = [56.0, 5.8, 47.2, 15.0]\n",
    "bbox_wgs84_konstanz = [47.9, 8.9, 47.6, 9.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d72232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sis-health-vector\"\n",
    "request = {\n",
    "    \"variable\": [\n",
    "        \"suitability\",\n",
    "        \"season_length\"\n",
    "    ],\n",
    "    \"experiment\": [\n",
    "        \"rcp4_5\",\n",
    "        \"rcp8_5\"\n",
    "    ],\n",
    "    \"ensemble_statistic\": [\n",
    "        \"ensemble_members_average\",\n",
    "        \"ensemble_members_standard_deviation\"\n",
    "    ],\n",
    "    \"area\": bbox_wgs84_deutschland\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea2a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 11:07:03,565 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 11:07:03,567 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 11:07:03,568 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 11:07:03,568 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run this cell to download the dataset:\n",
    "\n",
    "def main_retrieve():\n",
    "    dataset_filename = f\"{dataset}.zip\"\n",
    "    dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "\n",
    "    # Download the dataset only if the dataset has not been downloaded before\n",
    "    if not os.path.isfile(dataset_filepath):\n",
    "        # Download the dataset with the defined request parameters\n",
    "        client.retrieve(dataset, request, dataset_filepath)\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = main()\n",
    "    main_retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e667b1",
   "metadata": {},
   "source": [
    "### 2.3 Extract the Zip folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80dd9e85-f124-4457-808e-b6ff3df3989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is not empty. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "dataset_filename = f\"{dataset}.zip\"\n",
    "dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "extract_folder = working_folder\n",
    "\n",
    "# Extract the zip file\n",
    "try:\n",
    "    os.makedirs(extract_folder, exist_ok=True)\n",
    "    \n",
    "    if not os.listdir(extract_folder):\n",
    "        with zipfile.ZipFile(dataset_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_folder)\n",
    "            print(f\"Successfully extracted files to: {extract_folder}\")\n",
    "    else:\n",
    "        print(\"Folder is not empty. Skipping extraction.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {dataset_filepath} was not found.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(f\"Error: The file {dataset_filepath} is not a valid zip file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd360159",
   "metadata": {},
   "source": [
    "## 3. Data Processing and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d9fa9",
   "metadata": {},
   "source": [
    "### 3.1 Recording of available RCP scenarios and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc8601e-5782-4b6c-8d2a-20cc71747544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>path</th>\n",
       "      <th>variable</th>\n",
       "      <th>rcp</th>\n",
       "      <th>statistic</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mosquito_seas_rcp45_mean_v1.0.area-subset.56.0...</td>\n",
       "      <td>.\\data\\sis-health-vector\\working\\mosquito_seas...</td>\n",
       "      <td>seas</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>mean</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mosquito_seas_rcp45_stdev_v1.0.area-subset.56....</td>\n",
       "      <td>.\\data\\sis-health-vector\\working\\mosquito_seas...</td>\n",
       "      <td>seas</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>stdev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mosquito_seas_rcp85_mean_v1.0.area-subset.56.0...</td>\n",
       "      <td>.\\data\\sis-health-vector\\working\\mosquito_seas...</td>\n",
       "      <td>seas</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>mean</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mosquito_seas_rcp85_stdev_v1.0.area-subset.56....</td>\n",
       "      <td>.\\data\\sis-health-vector\\working\\mosquito_seas...</td>\n",
       "      <td>seas</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>stdev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mosquito_suit_rcp45_mean_v1.0.area-subset.56.0...</td>\n",
       "      <td>.\\data\\sis-health-vector\\working\\mosquito_suit...</td>\n",
       "      <td>suit</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>mean</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mosquito_suit_rcp45_stdev_v1.0.area-subset.56....</td>\n",
       "      <td>.\\data\\sis-health-vector\\working\\mosquito_suit...</td>\n",
       "      <td>suit</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>stdev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mosquito_suit_rcp85_mean_v1.0.area-subset.56.0...</td>\n",
       "      <td>.\\data\\sis-health-vector\\working\\mosquito_suit...</td>\n",
       "      <td>suit</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>mean</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mosquito_suit_rcp85_stdev_v1.0.area-subset.56....</td>\n",
       "      <td>.\\data\\sis-health-vector\\working\\mosquito_suit...</td>\n",
       "      <td>suit</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>stdev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  mosquito_seas_rcp45_mean_v1.0.area-subset.56.0...   \n",
       "1  mosquito_seas_rcp45_stdev_v1.0.area-subset.56....   \n",
       "2  mosquito_seas_rcp85_mean_v1.0.area-subset.56.0...   \n",
       "3  mosquito_seas_rcp85_stdev_v1.0.area-subset.56....   \n",
       "4  mosquito_suit_rcp45_mean_v1.0.area-subset.56.0...   \n",
       "5  mosquito_suit_rcp45_stdev_v1.0.area-subset.56....   \n",
       "6  mosquito_suit_rcp85_mean_v1.0.area-subset.56.0...   \n",
       "7  mosquito_suit_rcp85_stdev_v1.0.area-subset.56....   \n",
       "\n",
       "                                                path variable    rcp  \\\n",
       "0  .\\data\\sis-health-vector\\working\\mosquito_seas...     seas  rcp45   \n",
       "1  .\\data\\sis-health-vector\\working\\mosquito_seas...     seas  rcp45   \n",
       "2  .\\data\\sis-health-vector\\working\\mosquito_seas...     seas  rcp85   \n",
       "3  .\\data\\sis-health-vector\\working\\mosquito_seas...     seas  rcp85   \n",
       "4  .\\data\\sis-health-vector\\working\\mosquito_suit...     suit  rcp45   \n",
       "5  .\\data\\sis-health-vector\\working\\mosquito_suit...     suit  rcp45   \n",
       "6  .\\data\\sis-health-vector\\working\\mosquito_suit...     suit  rcp85   \n",
       "7  .\\data\\sis-health-vector\\working\\mosquito_suit...     suit  rcp85   \n",
       "\n",
       "  statistic version  \n",
       "0      mean     1.0  \n",
       "1     stdev     1.0  \n",
       "2      mean     1.0  \n",
       "3     stdev     1.0  \n",
       "4      mean     1.0  \n",
       "5     stdev     1.0  \n",
       "6      mean     1.0  \n",
       "7     stdev     1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def meta(filename):\n",
    "    match = re.search(r'mosquito_(suit|seas)_(rcp\\d{2})_(\\w+)_v(\\d+\\.\\d+)\\.', filename) # For subset area\n",
    "    if not match:\n",
    "        raise ValueError(\"the given filename does not fit the expected naming scheme\")\n",
    "        \n",
    "    return dict(\n",
    "        filename = filename,\n",
    "        path = os.path.join(working_folder, filename),\n",
    "        variable = match.group(1),\n",
    "        rcp = match.group(2),\n",
    "        statistic = match.group(3),\n",
    "        version = match.group(4),\n",
    "    )\n",
    "\n",
    "nc_files = [meta(f) for f in os.listdir(working_folder) if f.endswith('.nc')]\n",
    "\n",
    "df_nc_files = pd.DataFrame.from_dict(nc_files)\n",
    "df_nc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ccfa980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████████████████████▋                                                                                                                                                                                   | 1/8 [00:08<00:56,  8.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████████████████████████████████████▎                                                                                                                                                         | 2/8 [00:16<00:48,  8.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 3/8 [00:24<00:40,  8.10s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m         path \u001b[38;5;241m=\u001b[39m nc_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariables not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m [netcdf_to_dataframe(nc_file) \u001b[38;5;28;01mfor\u001b[39;00m nc_file \u001b[38;5;129;01min\u001b[39;00m tqdm(nc_files)]\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Kombiniere alle Daten in eine Tabelle\u001b[39;00m\n\u001b[0;32m     58\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dataframes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     52\u001b[0m         path \u001b[38;5;241m=\u001b[39m nc_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariables not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m [\u001b[43mnetcdf_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnc_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m nc_file \u001b[38;5;129;01min\u001b[39;00m tqdm(nc_files)]\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Kombiniere alle Daten in eine Tabelle\u001b[39;00m\n\u001b[0;32m     58\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dataframes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 41\u001b[0m, in \u001b[0;36mnetcdf_to_dataframe\u001b[1;34m(nc_file)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(temperature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]):\n\u001b[0;32m     34\u001b[0m             rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     35\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: time[t],\n\u001b[0;32m     36\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m: lat[i],\n\u001b[0;32m     37\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m: lon[j],\n\u001b[0;32m     38\u001b[0m                 variable_column_name: temperature[t, i, j]\n\u001b[0;32m     39\u001b[0m             })\n\u001b[1;32m---> 41\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mstr\u001b[39m))\n\u001b[0;32m     43\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mF:\\OneDrive - str.ucture GmbH\\General\\CoKLIMAx (Phase 2)\\CoKLIMAx-II\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m         arrays,\n\u001b[0;32m    861\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m     )\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mF:\\OneDrive - str.ucture GmbH\\General\\CoKLIMAx (Phase 2)\\CoKLIMAx-II\\myenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mF:\\OneDrive - str.ucture GmbH\\General\\CoKLIMAx (Phase 2)\\CoKLIMAx-II\\myenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:837\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    835\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], abc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m--> 837\u001b[0m     arr, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_list_of_dict_to_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m    839\u001b[0m     arr, columns \u001b[38;5;241m=\u001b[39m _list_of_series_to_arrays(data, columns)\n",
      "File \u001b[1;32mF:\\OneDrive - str.ucture GmbH\\General\\CoKLIMAx (Phase 2)\\CoKLIMAx-II\\myenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:917\u001b[0m, in \u001b[0;36m_list_of_dict_to_arrays\u001b[1;34m(data, columns)\u001b[0m\n\u001b[0;32m    915\u001b[0m     gen \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[0;32m    916\u001b[0m     sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m--> 917\u001b[0m     pre_cols \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_unique_multiple_list_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(pre_cols)\n\u001b[0;32m    920\u001b[0m \u001b[38;5;66;03m# assure that they are of the base dict class and not of derived\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# classes\u001b[39;00m\n",
      "File \u001b[1;32mlib.pyx:367\u001b[0m, in \u001b[0;36mpandas._libs.lib.fast_unique_multiple_list_gen\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mF:\\OneDrive - str.ucture GmbH\\General\\CoKLIMAx (Phase 2)\\CoKLIMAx-II\\myenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:915\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;124;03mConvert list of dicts to numpy arrays\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03mcolumns : Index\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m     gen \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[0;32m    916\u001b[0m     sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[0;32m    917\u001b[0m     pre_cols \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_unique_multiple_list_gen(gen, sort\u001b[38;5;241m=\u001b[39msort)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset, num2date\n",
    "from tqdm import tqdm\n",
    "\n",
    "def netcdf_to_dataframe(nc_file):\n",
    "    \n",
    "    dataset = Dataset(nc_file['path'], 'r')\n",
    "    variable = nc_file['variable']\n",
    "\n",
    "    if variable == 'suit':\n",
    "        variable_name = 'suitability'\n",
    "    elif variable == 'seas':\n",
    "        variable_name = 'season_length'\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected variable: {variable}\")\n",
    "    \n",
    "    if variable_name in dataset.variables and 'time' in dataset.variables:\n",
    "        temperature = dataset.variables[variable_name][:]\n",
    "        time = dataset.variables['time'][:]\n",
    "        lat = dataset.variables['lat'][:]\n",
    "        lon = dataset.variables['lon'][:]\n",
    "        \n",
    "        time_units = dataset.variables['time'].units\n",
    "        time_calendar = dataset.variables['time'].calendar if hasattr(dataset.variables['time'], 'calendar') else 'standard'\n",
    "        time = num2date(time, units=time_units, calendar=time_calendar)\n",
    "        \n",
    "        variable_column_name = f\"{variable}-{nc_file['rcp']}-{nc_file['statistic']}\"\n",
    "        \n",
    "        rows = []\n",
    "        for t in range(temperature.shape[0]):\n",
    "            for i in range(temperature.shape[1]):\n",
    "                for j in range(temperature.shape[2]):\n",
    "                    rows.append({\n",
    "                        'time': time[t],\n",
    "                        'latitude': lat[i],\n",
    "                        'longitude': lon[j],\n",
    "                        variable_column_name: temperature[t, i, j]\n",
    "                    })\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "        df['time'] = pd.to_datetime(df['time'].map(str))\n",
    "        df['latitude'] = pd.to_numeric(df['latitude'])\n",
    "        df['longitude'] = pd.to_numeric(df['longitude'])\n",
    "        # df[variable_column_name] = pd.to_numeric(df[variable_column_name])\n",
    "        \n",
    "        # Setze den Index auf time, latitude und longitude\n",
    "        return df.set_index(['time', 'latitude', 'longitude'])\n",
    "\n",
    "    else:\n",
    "        # Zugriff auf das nc_file Dictionary separat aufgelöst\n",
    "        path = nc_file['path']\n",
    "        raise ValueError(f\"Variables not found in {path}\")\n",
    "\n",
    "dataframes = [netcdf_to_dataframe(nc_file) for nc_file in tqdm(nc_files)]\n",
    "\n",
    "# Kombiniere alle Daten in eine Tabelle\n",
    "df = pd.concat(dataframes, axis=1)\n",
    "df\n",
    "\n",
    "## Export and compile takes more than 30s, error in sphinx\n",
    "## Runs without error locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58cd5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = os.path.join(csv_folder, 'sis-health-vector.csv.zip')\n",
    "\n",
    "\n",
    "# if not os.path.isfile(csv_path):\n",
    "#     df.to_csv(csv_path, sep=',', encoding='utf8', compression='zip')\n",
    "#     print(f\"Summary data exported to {csv_path}\")\n",
    "# else:\n",
    "#     print(f\"{csv_path} file already exists. Skipping export.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}