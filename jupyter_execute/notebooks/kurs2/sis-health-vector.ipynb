{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34347356",
   "metadata": {},
   "source": [
    "# SIS Health Vector\n",
    "\n",
    "Eignung für das Vorkommen und die saisonale Aktivität der Tigermücke (Aedes albopictus) in Europa\n",
    "\n",
    "Dieses Skript verarbeitet den Datensatz **SIS Health Vector** aus dem Copernics Climate Data Store. Der Datensatz enthält Informationen zu der Eignung der Umweltbedingungen sowie der saisonalen Aktivität der Tigermücke. Der Datensatz wurde im Rahmen des C3S European Health Service entwickelt. Die Informationen sind für unterschiedliche zukünftige Zeiträume und Klimawandelszenarien verfügbar.\n",
    "\n",
    "**Informationen zum Datensatz**: \n",
    "\n",
    "* Source: [SIS Health Vector](https://cds.climate.copernicus.eu/datasets/sis-health-vector?tab=overview)\n",
    "* Author: T. Tewes (Stadt Konstanz) \n",
    "* Resolution: 0.1° x 0.1°\n",
    "* Notebook-Version: 1.1 (Updated: December 02, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc12136",
   "metadata": {},
   "source": [
    "## 1. Specifying the paths and working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b939873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' ---- Hier die Verzeichnisse angeben ---- '''\n",
    "download_folder = r\".\\data\\sis-health-vector\\download\"\n",
    "working_folder = r\".\\data\\sis-health-vector\\working\"\n",
    "geotiff_folder = r\".\\data\\sis-health-vector\\geotiff\"\n",
    "csv_folder = r\".\\data\\sis-health-vector\\csv\"\n",
    "output_folder = r\".\\data\\sis-health-vector\\output\"\n",
    "''' ----- Ende der Eingaben ---- '''\n",
    "\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "os.makedirs(working_folder, exist_ok=True)\n",
    "os.makedirs(geotiff_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084bec7",
   "metadata": {},
   "source": [
    "## 2. Download and Extract Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59f15a",
   "metadata": {},
   "source": [
    "### 2.1 API Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef08eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "def main():\n",
    "    api_key = \"fdae60fd-35d4-436f-825c-c63fedab94a4\"\n",
    "    api_url = \"https://cds.climate.copernicus.eu/api\"\n",
    "    client = cdsapi.Client(url=api_url, key=api_key)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77ceda",
   "metadata": {},
   "source": [
    "### 2.2 Request Definition and Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6c35ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55.2, 5.7, 47.1, 15.2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define additional request fields to ensure the request stays within the file size limit.\n",
    "# These coordinates were obtained using the BBox Extractor tool:\n",
    "# https://str-ucture.github.io/bbox-extractor/\n",
    "\n",
    "bbox_wgs84_deutschland = [56.0, 5.8, 47.2, 15.0]\n",
    "bbox_wgs84_konstanz = [47.9, 8.9, 47.6, 9.3]\n",
    "\n",
    "# Alternatively, use a shapefile for precise geographic filtering\n",
    "import geopandas as gpd\n",
    "import math\n",
    "\n",
    "# Example: Load shapefile of Konstanz (WGS84 projection)\n",
    "de_shapefile = r\"./shapefiles/de_boundary.shp\"\n",
    "de_gdf = gpd.read_file(de_shapefile)\n",
    "de_bounds = de_gdf.total_bounds\n",
    "\n",
    "# Adjust and buffer\n",
    "de_bounds_adjusted = [(math.floor(de_bounds[0]* 10)/10)-0.1,\n",
    "                      (math.floor(de_bounds[1]* 10)/10)-0.1,\n",
    "                      (math.ceil(de_bounds[2]* 10)/10)+0.1,\n",
    "                      (math.ceil(de_bounds[3]* 10)/10)+0.1]\n",
    "\n",
    "bbox_de_bounds_adjusted = [de_bounds_adjusted[3], de_bounds_adjusted[0],\n",
    "                           de_bounds_adjusted[1], de_bounds_adjusted[2]]\n",
    "\n",
    "bbox_de_bounds_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d72232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sis-health-vector\"\n",
    "request = {\n",
    "    \"variable\": [\n",
    "        \"suitability\",\n",
    "        \"season_length\"\n",
    "    ],\n",
    "    \"experiment\": [\n",
    "        \"rcp4_5\",\n",
    "        \"rcp8_5\"\n",
    "    ],\n",
    "    \"ensemble_statistic\": [\n",
    "        \"ensemble_members_average\",\n",
    "        \"ensemble_members_standard_deviation\"\n",
    "    ],\n",
    "    \"area\": bbox_de_bounds_adjusted\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea2a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 17:26:34,911 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 17:26:34,913 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 17:26:34,913 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 17:26:34,914 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run this cell to download the dataset:\n",
    "\n",
    "def main_retrieve():\n",
    "    dataset_filename = f\"{dataset}.zip\"\n",
    "    dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "\n",
    "    # Download the dataset only if the dataset has not been downloaded before\n",
    "    if not os.path.isfile(dataset_filepath):\n",
    "        # Download the dataset with the defined request parameters\n",
    "        client.retrieve(dataset, request, dataset_filepath)\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = main()\n",
    "    main_retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e667b1",
   "metadata": {},
   "source": [
    "### 2.3 Extract the Zip folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80dd9e85-f124-4457-808e-b6ff3df3989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is not empty. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "dataset_filename = f\"{dataset}.zip\"\n",
    "dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "\n",
    "# Extract the zip file\n",
    "try:\n",
    "    os.makedirs(working_folder, exist_ok=True)\n",
    "    \n",
    "    if not os.listdir(working_folder):\n",
    "        with zipfile.ZipFile(dataset_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(working_folder)\n",
    "            print(f\"Successfully extracted files to: {working_folder}\")\n",
    "    else:\n",
    "        print(\"Folder is not empty. Skipping extraction.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {dataset_filepath} was not found.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(f\"Error: The file {dataset_filepath} is not a valid zip file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22734a57",
   "metadata": {},
   "source": [
    "## 3. Read the netCDF file and print the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc8601e-5782-4b6c-8d2a-20cc71747544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def meta(filename):\n",
    "    match = re.search(r'mosquito_(suit|seas)_(rcp\\d{2})_(\\w+)_v(\\d+\\.\\d+)\\.', filename)\n",
    "    if not match:\n",
    "        raise ValueError(\"the given filename does not fit the expected naming scheme\")\n",
    "    \n",
    "    var = match.group(1)\n",
    "    return dict(\n",
    "        filename=filename,\n",
    "        path=os.path.join(working_folder, filename),\n",
    "        variable=var,\n",
    "        varilable_name=\"season_length\" if var == 'seas' else \"suitability\",\n",
    "        rcp = match.group(2),\n",
    "        statistic = match.group(3),\n",
    "        version = match.group(4),\n",
    "    )\n",
    "\n",
    "# Create DataFrame from the list of files inside the extracted directory\n",
    "nc_files = [meta(f) for f in os.listdir(working_folder) if f.endswith('.nc')]\n",
    "df_nc_files = pd.DataFrame.from_dict(nc_files)\n",
    "\n",
    "# Modify pandas display options\n",
    "pd.options.display.max_colwidth = 30\n",
    "\n",
    "# Display the DataFrame\n",
    "# df_nc_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05d19f",
   "metadata": {},
   "source": [
    "### 3.1 For variable = 'seas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e17f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available variables: ['season_length', 'height', 'lat', 'lon', 'time']\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "# Open the NetCDF file in read mode\n",
    "nc_dataset = nc.Dataset(df_nc_files['path'][0], mode='r')\n",
    "\n",
    "# List all variables in the dataset\n",
    "variables_list = nc_dataset.variables.keys()\n",
    "print(f\"Available variables: {list(variables_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6da6b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Variable Name</td>\n",
       "      <td>season_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shape</td>\n",
       "      <td>(100, 82, 95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable Info</td>\n",
       "      <td>season_length(time, lat, lon)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Units</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Long Name</td>\n",
       "      <td>Ensemble members average o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Description                        Remarks\n",
       "0  Variable Name                  season_length\n",
       "1      Data Type                        float32\n",
       "2          Shape                  (100, 82, 95)\n",
       "3  Variable Info  season_length(time, lat, lon)\n",
       "4          Units                              1\n",
       "5      Long Name  Ensemble members average o..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define variable name from available variables and read variable data\n",
    "variable_name = 'season_length'\n",
    "variable_data = nc_dataset[variable_name]\n",
    "\n",
    "# Generate summary of the primary variable\n",
    "summary = {\n",
    "    \"Variable Name\": variable_name,\n",
    "    \"Data Type\": variable_data.dtype,\n",
    "    \"Shape\": variable_data.shape,\n",
    "    \"Variable Info\": f\"{variable_name}({', '.join(variable_data.dimensions)})\",\n",
    "    \"Units\": getattr(variable_data, \"units\", \"N/A\"),\n",
    "    \"Long Name\": getattr(variable_data, \"long_name\", \"N/A\"),\n",
    "}\n",
    "\n",
    "# Display dataset summary as a DataFrame for better visualization\n",
    "nc_summary = pd.DataFrame(list(summary.items()), columns=['Description', 'Remarks'])\n",
    "\n",
    "# Display the summary DataFrame\n",
    "nc_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62195119",
   "metadata": {},
   "source": [
    "### 3.2 For variable = 'suit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f21789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available variables: ['suitability', 'height', 'lat', 'lon', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Open the NetCDF file in read mode\n",
    "nc_dataset = nc.Dataset(df_nc_files['path'][4], mode='r')\n",
    "\n",
    "# List all variables in the dataset\n",
    "variables_list = nc_dataset.variables.keys()\n",
    "print(f\"Available variables: {list(variables_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffcd9bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Variable Name</td>\n",
       "      <td>suitability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shape</td>\n",
       "      <td>(100, 82, 95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable Info</td>\n",
       "      <td>suitability(time, lat, lon)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Units</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Long Name</td>\n",
       "      <td>Ensemble members average o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Description                        Remarks\n",
       "0  Variable Name                    suitability\n",
       "1      Data Type                        float32\n",
       "2          Shape                  (100, 82, 95)\n",
       "3  Variable Info    suitability(time, lat, lon)\n",
       "4          Units                              1\n",
       "5      Long Name  Ensemble members average o..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define variable name from available variables and read variable data\n",
    "variable_name = 'suitability'\n",
    "variable_data = nc_dataset[variable_name]\n",
    "\n",
    "# Generate summary of the primary variable\n",
    "summary = {\n",
    "    \"Variable Name\": variable_name,\n",
    "    \"Data Type\": variable_data.dtype,\n",
    "    \"Shape\": variable_data.shape,\n",
    "    \"Variable Info\": f\"{variable_name}({', '.join(variable_data.dimensions)})\",\n",
    "    \"Units\": getattr(variable_data, \"units\", \"N/A\"),\n",
    "    \"Long Name\": getattr(variable_data, \"long_name\", \"N/A\"),\n",
    "}\n",
    "\n",
    "# Display dataset summary as a DataFrame for better visualization\n",
    "nc_summary = pd.DataFrame(list(summary.items()), columns=['Description', 'Remarks'])\n",
    "\n",
    "# Display the summary DataFrame\n",
    "nc_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024e622",
   "metadata": {},
   "source": [
    "## 4. Export Dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e8e598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from tqdm import tqdm\n",
    "\n",
    "def netcdf_to_dataframe(\n",
    "    nc_file,\n",
    "    bounding_box=None):\n",
    "    \"\"\"\n",
    "    Converts a netCDF file to a DataFrame, optionally filtering by a bounding box.\n",
    "\n",
    "    Parameters:\n",
    "        nc_file (dict): Dictionary with keys 'filename', 'path', 'variable', 'variable_name', 'rcp', 'statistic', 'version'.\n",
    "        bbox (list): Bounding box as [lon_min, lat_min, lon_max, lat_max] (optional).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with time, latitude, longitude, and the variable's values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the netCDF file\n",
    "        nc_dataset = nc.Dataset(nc_file['path'], 'r')\n",
    "        lon = nc_dataset['lon'][:]\n",
    "        lat = nc_dataset['lat'][:]\n",
    "        \n",
    "        # Retrieve the variable name\n",
    "        variable = nc_file['variable']\n",
    "        if variable == 'suit':\n",
    "            variable_name = 'suitability'\n",
    "        elif variable == 'seas':\n",
    "            variable_name = 'season_length'\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected variable: {variable}\")\n",
    "        \n",
    "        # Extract time variable and convert it to readable dates\n",
    "        time_var = nc_dataset.variables['time']\n",
    "        time_units = time_var.units\n",
    "        time_calendar = getattr(time_var, \"calendar\", \"standard\")\n",
    "        cftime = nc.num2date(time_var[:], units=time_units, calendar=time_calendar)\n",
    "\n",
    "        # Extract temperature/variable data\n",
    "        temperature_data = nc_dataset.variables[variable_name][:]\n",
    "        \n",
    "        # Filter by bounding box if provided\n",
    "        if bounding_box:\n",
    "            lon_min, lat_min, lon_max, lat_max = bounding_box\n",
    "            \n",
    "            indices_lat = np.where((lat >= lat_min) & (lat <= lat_max))[0]\n",
    "            indices_lon = np.where((lon >= lon_min) & (lon <= lon_max))[0]\n",
    "            \n",
    "            start_lat, end_lat = indices_lat[0], indices_lat[-1] + 1\n",
    "            start_lon, end_lon = indices_lon[0], indices_lon[-1] + 1\n",
    "            \n",
    "            filtered_lat = lat[start_lat:end_lat]\n",
    "            filtered_lon = lon[start_lon:end_lon]\n",
    "            temperature_data_subset = temperature_data[:, start_lat:end_lat, start_lon:end_lon]\n",
    "            \n",
    "            # # Filter the data (Alternative approach)\n",
    "            # # Suitable for irregularly spaced lat/lon values (curvilinear grids, non-uniform sampling)\n",
    "            # filtered_lat = lat[indices_lat]\n",
    "            # filtered_lon = lon[indices_lon]\n",
    "            # temperature_data_subset = temperature_data[:, indices_lat, :][:, :, indices_lon]\n",
    "        else:\n",
    "            filtered_lat = lat\n",
    "            filtered_lon = lon\n",
    "            temperature_data_subset = temperature_data\n",
    "            \n",
    "        # Create a column name for the variable\n",
    "        variable_column_name = f\"{variable}-{nc_file['rcp']}-{nc_file['statistic']}\"\n",
    "        \n",
    "        \n",
    "        # Create rows for the DataFrame\n",
    "        rows = []\n",
    "        for t in range(temperature_data_subset.shape[0]):\n",
    "            for i in range(temperature_data_subset.shape[1]):\n",
    "                for j in range(temperature_data_subset.shape[2]):\n",
    "                    if not np.ma.is_masked(temperature_data_subset[t, i, j]):\n",
    "                        rows.append({\n",
    "                            'time': cftime[t],\n",
    "                            'latitude': filtered_lat[i],\n",
    "                            'longitude': filtered_lon[j],\n",
    "                            variable_column_name: temperature_data_subset[t, i, j]\n",
    "                        })\n",
    "                    \n",
    "        \n",
    "        # Create a DataFrame from the rows\n",
    "        df = pd.DataFrame(rows)\n",
    "        df['time'] = pd.to_datetime(df['time'].map(str))\n",
    "        df['latitude'] = pd.to_numeric(df['latitude'])\n",
    "        df['longitude'] = pd.to_numeric(df['longitude'])\n",
    "        df[variable_column_name] = pd.to_numeric(df[variable_column_name])\n",
    "        \n",
    "        # Set the index to time, latitude, and longitude\n",
    "        return df.set_index(['time', 'latitude', 'longitude'])\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"KeyError: Missing required variable in the netCDF file: {e}\")\n",
    "    finally:\n",
    "        # Ensure the dataset is closed\n",
    "        nc_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d5c44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at .\\data\\sis-health-vector\\csv\\mosquito_seas_rcp45_mean.csv. Skipping export.\n",
      "File already exists at .\\data\\sis-health-vector\\csv\\mosquito_seas_rcp45_stdev.csv. Skipping export.\n",
      "File already exists at .\\data\\sis-health-vector\\csv\\mosquito_seas_rcp85_mean.csv. Skipping export.\n",
      "File already exists at .\\data\\sis-health-vector\\csv\\mosquito_seas_rcp85_stdev.csv. Skipping export.\n",
      "File already exists at .\\data\\sis-health-vector\\csv\\mosquito_suit_rcp45_mean.csv. Skipping export.\n",
      "File already exists at .\\data\\sis-health-vector\\csv\\mosquito_suit_rcp45_stdev.csv. Skipping export.\n",
      "File already exists at .\\data\\sis-health-vector\\csv\\mosquito_suit_rcp85_mean.csv. Skipping export.\n",
      "File already exists at .\\data\\sis-health-vector\\csv\\mosquito_suit_rcp85_stdev.csv. Skipping export.\n"
     ]
    }
   ],
   "source": [
    "# Create individual DataFrame and Export as individual CSV files\n",
    "for nc_file in nc_files:\n",
    "    csv_filename = f\"mosquito_{nc_file['variable']}_{nc_file['rcp']}_{nc_file['statistic']}.csv\"\n",
    "    csv_path = os.path.join(csv_folder, csv_filename)\n",
    "    \n",
    "    if not os.path.isfile(csv_path):\n",
    "        df = netcdf_to_dataframe(nc_file)\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Data exported successfully to {csv_path}\")\n",
    "    else:\n",
    "        print(f\"File already exists at {csv_path}. Skipping export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8e496bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at .\\data\\sis-health-vector\\csv\\sis-health-vector-merged.csv.zip. Skipping export.\n"
     ]
    }
   ],
   "source": [
    "# Create combined DataFrame and Export as merged CSV file\n",
    "csv_filename = 'sis-health-vector-merged.csv.zip'\n",
    "csv_path = os.path.join(csv_folder, csv_filename)\n",
    "\n",
    "if not os.path.isfile(csv_path):\n",
    "    dataframes = [netcdf_to_dataframe(nc_file) for nc_file in nc_files]\n",
    "    df = pd.concat(dataframes, axis=1)\n",
    "    df.to_csv(csv_path, sep=',', encoding='utf8', compression='zip')\n",
    "else:\n",
    "    print(f\"File already exists at {csv_path}. Skipping export.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}