{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ebf1ed",
   "metadata": {},
   "source": [
    "# Seewassertemperatur aus Satellitendaten abgeleitet\n",
    "\n",
    "Dieses Datenset liefert tägliche Werte der Oberflächenwassertemperatur von Seen (LSWT) am Vormittag, abgeleitet aus Satellitendaten, zusammen mit zugehöriger Unsicherheit und Qualitätsstufen. Die Daten, die von den ATSR- und AVHRR-Sensoren stammen, wurden zur Konsistenzanpassung bias-korrigiert und können aufgrund fehlender Beobachtungen Lücken enthalten. LSWT ist eine essenzielle Klimavariable, die für das Verständnis der Seeökologie, hydrologischer Prozesse und großräumiger Klimawechselwirkungen von entscheidender Bedeutung ist. Die Datenentwicklung wurde durch das UK NERC GloboLakes-Projekt unterstützt, und zukünftige Verbesserungen erfolgen im Rahmen der ESA Climate Change Initiative.\n",
    "\n",
    "**Schnellnavigation:**\n",
    "* [Herunterladen und Entpacken des Datensatzes](#herunterladen-und-entpacken-des-datensatzes)\n",
    "* [NetCDF4-Dateien zu einer einzigen NetCDF4-Datei zusammenführen](#netcdf4-dateien-zu-einer-einzigen-netcdf4-datei-zusammenfuhren)\n",
    "* [Untersuchen der Metadaten der netCDF4-Datei](#untersuchen-der-metadaten-der-netcdf4-datei)\n",
    "* [Exportieren der Zeitreihe im csv-Format](#exportieren-der-zeitreihe-im-csv-format)\n",
    "* [Analyse und Visualisierung Optionen](#analyse-und-visualisierung-optionen)\n",
    "* [Exportieren der NetCDF4-Datei nach GeoTIFF](#exportieren-der-netcdf4-datei-nach-geotiff)\n",
    "* [Zusätzliche Visualisierung mit einem Kalenderdiagramm](#zusatzliche-visualisierung-mit-einem-kalenderdiagramm)\n",
    "\n",
    "**Information on Dataset:**\n",
    "* Quelle: <a href=\"https://cds.climate.copernicus.eu/datasets/satellite-lake-water-temperature?tab=overview\" target=\"_blank\">Satellite Lake Water Temperature</a>\n",
    "* Author: T. Tewes (City of Konstanz)\n",
    "* Notebook Version: 1.3 (Updated: January 17, 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacce046",
   "metadata": {},
   "source": [
    "## 1. Festlegen der Pfade und Arbeitsverzeichnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' ---- Verzeichnisse hier angeben ---- '''\n",
    "download_folder = r\".\\data\\satellite-lake-water-temperature\\download\"\n",
    "working_folder = r\".\\data\\satellite-lake-water-temperature\\working\"\n",
    "geotiff_folder = r\".\\data\\satellite-lake-water-temperature\\geotiff\"\n",
    "csv_folder = r\".\\data\\satellite-lake-water-temperature\\csv\"\n",
    "output_folder = r\".\\data\\satellite-lake-water-temperature\\output\"\n",
    "''' ----- Ende der Angaben ---- '''\n",
    "\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "os.makedirs(working_folder, exist_ok=True)\n",
    "os.makedirs(geotiff_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4fbb35",
   "metadata": {},
   "source": [
    "## 2. Herunterladen und Entpacken des Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9519e01",
   "metadata": {},
   "source": [
    "### 2.1 Authentifizierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507616bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "def main():\n",
    "    # API-Key für die Authentifizierung\n",
    "    api_key = \"fdae60fd-35d4-436f-825c-c63fedab94a4\"\n",
    "    api_url = \"https://cds.climate.copernicus.eu/api\"\n",
    "\n",
    "    # Erstellung des CDS-API-Clients\n",
    "    client = cdsapi.Client(url=api_url, key=api_key)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233eefdd",
   "metadata": {},
   "source": [
    "### 2.2 Definieren Sie die „request“ und laden Sie den Datensatz herunter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163b0fd",
   "metadata": {},
   "source": [
    "Definieren Sie zusätzliche Anfragefelder, um sicherzustellen, dass die Anfrage innerhalb der Dateigrößenbeschränkung bleibt. Bei der Arbeit mit Geodaten oder APIs, die Karten- oder Satellitenbilder zurückgeben, kann die Begrenzung des geografischen Interessengebiets verhindern, dass Anfragen zu groß werden und die Datei- oder Verarbeitungsgrenzen überschreiten. Begrenzungsrahmen (Bounding Boxes) werden verwendet, um das geografische Gebiet für solche Anfragen festzulegen.\n",
    "\n",
    "Die untenstehenden Koordinaten wurden mit dem Tool <a href=\"https://str-ucture.github.io/bbox-extractor/\" target=\"_blank\">BBox Extractor</a> ermittelt.\n",
    "\n",
    "*BBox Extractor ist ein webbasiertes Tool, das Benutzern hilft, interaktiv Begrenzungsrahmen-Koordinaten im WGS84-Format (Breite/Länge) auszuwählen und zu generieren. Dies ist besonders nützlich für APIs oder Datensätze, die eine Eingabe eines geografischen Gebiets erfordern*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren der Begrenzungsrahmen-Koordinaten (WGS84-Format) für die Region Bodensee.\n",
    "# Das Koordinatenformat lautet: [Norden, Westen, Süden, Osten]\n",
    "bbox_wgs84_constance = [48.0, 8.7, 47.3, 9.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie das Jahr von Interesse für die Datenanforderung an.\n",
    "# Die entsprechende Datenversion hängt vom Jahr ab.\n",
    "year = 2007\n",
    "\n",
    "# Bestimmen Sie die Datenversion basierend auf dem Jahr:\n",
    "# Version \"4_5_1\" wird für Jahre bis 2020 verwendet, und \"4_5_2\" für spätere Jahre.\n",
    "if 1900 <= year <= 2100:  # Überprüfen Sie den gültigen Jahresbereich für Robustheit.\n",
    "    version = \"4_5_1\" if year <= 2020 else \"4_5_2\"\n",
    "else:\n",
    "    raise ValueError(f\"Ungültiges Jahr: {year}. Bitte geben Sie ein Jahr zwischen 1900 und 2100 an.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a199e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Datensatzes und der Request-Parameter\n",
    "dataset = \"satellite-lake-water-temperature\"\n",
    "request = {\n",
    "    \"variable\": \"all\",\n",
    "    \"year\": [f\"{year}\"],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ],\n",
    "    \"day\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\",\n",
    "        \"13\", \"14\", \"15\",\n",
    "        \"16\", \"17\", \"18\",\n",
    "        \"19\", \"20\", \"21\",\n",
    "        \"22\", \"23\", \"24\",\n",
    "        \"25\", \"26\", \"27\",\n",
    "        \"28\", \"29\", \"30\",\n",
    "        \"31\"\n",
    "    ],\n",
    "    \"version\": version,\n",
    "    \"area\": bbox_wgs84_constance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff16f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Führen Sie es aus, um den Datensatz herunterzuladen:\n",
    "def main_retrieve():\n",
    "    dataset_filename = f\"{dataset}_{request['year'][0]}.zip\"\n",
    "    dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "    \n",
    "    # Den Datensatz nur herunterladen, wenn er noch nicht heruntergeladen wurde\n",
    "    if not os.path.isfile(dataset_filepath):\n",
    "        # Rufen Sie den CDS-Client nur auf, wenn der Datensatz noch nicht heruntergeladen wurde.\n",
    "        client = main()\n",
    "        # Den Datensatz mit den definierten Anforderungsparametern herunterladen\n",
    "        client.retrieve(dataset, request, dataset_filepath)\n",
    "    else:\n",
    "        print(\"Datensatz bereits heruntergeladen.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main_retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df293df1",
   "metadata": {},
   "source": [
    "### 2.3 Extrahieren Sie die ZIP-Dateien in Ordner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Erstellen des Dateinamens und des Dateipfads für die ZIP-Datei des Datensatzes\n",
    "dataset_filename = f\"{dataset}_{year}.zip\"\n",
    "dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "\n",
    "# Erstellen Sie einen Ordner zum Extrahieren der ZIP-Datei basierend auf dem ausgewählten Jahr\n",
    "extract_folder = os.path.join(working_folder, str(year))\n",
    "\n",
    "# Entpacken der ZIP-Datei\n",
    "try:\n",
    "    os.makedirs(extract_folder, exist_ok=True)\n",
    "    \n",
    "    if not os.listdir(extract_folder):\n",
    "        # Versuchen Sie, die ZIP-Datei zu öffnen und zu extrahieren\n",
    "        with zipfile.ZipFile(dataset_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_folder)\n",
    "            print(f\"Dateien erfolgreich extrahiert nach: {extract_folder}\")\n",
    "    else:\n",
    "        print(\"Ordner ist nicht leer. Entpacken überspringen.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Fehler: Die Datei {dataset_filepath} wurde nicht gefunden.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(f\"Fehler: Die Datei {dataset_filepath} ist keine gültige ZIP-Datei.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ein unerwarteter Fehler ist aufgetreten: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6d514",
   "metadata": {},
   "source": [
    "## 3. NetCDF4-Dateien zu einer einzigen NetCDF4-Datei zusammenführen\n",
    "\n",
    "Viele **jährliche Datensätze** werden als tägliche NetCDF4-Dateien bereitgestellt, wobei jede Datei einen Tag des Jahres repräsentiert *(365 Dateien für normale Jahre, 366 Dateien für Schaltjahre)*. Die Verwaltung dieser zahlreichen Dateien kann mühsam sein, insbesondere beim Datenzugriff oder bei der Visualisierung.\n",
    "\n",
    "Um Arbeitsabläufe zu vereinfachen und die Effizienz der Datenverarbeitung zu verbessern, werden alle täglichen Datensätze eines bestimmten Jahres in einer **einzigen jährlichen NetCDF4-Datei** zusammengeführt. Diese Konsolidierung erleichtert die spätere Datenverarbeitung, beispielsweise für die Visualisierung oder statistische Auswertungen.\n",
    "\n",
    "> Wichtig: Tägliche Datensätze können spärliche oder fehlende Daten enthalten. Daher kann die zusammengeführte NetCDF4-Datei, die zusammengeführte GeoTIFF-Datei oder einzelne GeoTIFF-Dateien leere Zeitpunkte enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e34cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Definiere den Dateipfad für die zusammengeführte NetCDF-Datei (1 Datei pro Jahr)\n",
    "nc_filepath_merged = os.path.join(output_folder,f\"{dataset}_{year}.nc\")\n",
    "\n",
    "# Überprüfe, ob die zusammengeführte Datei bereits existiert\n",
    "if not os.path.isfile(nc_filepath_merged):\n",
    "    # Liste alle NetCDF-Dateien im Extrakt-Ordner auf\n",
    "    filename_list = os.listdir(extract_folder)\n",
    "\n",
    "    if not filename_list:\n",
    "        print(f\"Keine NetCDF-Dateien im Ordner {extract_folder} gefunden.\")\n",
    "    else:\n",
    "        try:\n",
    "            # Öffne und verknüpfe alle NetCDF-Dateien entlang der 'time'-Dimension\n",
    "            datasets = [xr.open_dataset(os.path.join(extract_folder, f)) for f in filename_list]\n",
    "            merged_dataset = xr.concat(datasets, dim='time')\n",
    "            \n",
    "            # Speichere den zusammengeführten Datensatz in der neuen NetCDF-Datei\n",
    "            merged_dataset.to_netcdf(nc_filepath_merged)\n",
    "            print(f\"Neue NetCDF4-Datei erstellt unter {nc_filepath_merged} für das Jahr {year}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei der Dateiverarbeitung: {e}\")\n",
    "else:\n",
    "    print(f\"Zusammengeführte NetCDF-Datei für das Jahr {year} existiert bereits. Überspringe Zusammenführung.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b517ae",
   "metadata": {},
   "source": [
    "## 4. Untersuchen der Metadaten der NetCDF4-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "# Definieren Sie den Dateipfad für den zusammengeführten netCDF-Datensatz\n",
    "nc_filename = f\"satellite-lake-water-temperature_{year}.nc\"\n",
    "nc_filepath = os.path.join(output_folder, nc_filename)\n",
    "\n",
    "# Öffnen der NetCDF-Datei im Lesemodus\n",
    "nc_dataset = nc.Dataset(nc_filepath_merged, mode=\"r\")\n",
    "\n",
    "# Auflisten aller Variablen im Datensatz\n",
    "variables_list = nc_dataset.variables.keys()\n",
    "print(f\"Verfügbare Variablen: {list(variables_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Variablennamen aus vorhandenen Variablen definieren und Variablendaten lesen\n",
    "variable_name = 'lake_surface_water_temperature'\n",
    "variable_data = nc_dataset[variable_name]\n",
    "\n",
    "# Erstellen einer Zusammenfassung der Hauptvariablen\n",
    "summary = {\n",
    "    \"Variablename\": variable_name,\n",
    "    \"Datentyp\": variable_data.dtype,\n",
    "    \"Form\": variable_data.shape,\n",
    "    \"Variableinfo\": f\"{variable_name}({', '.join(variable_data.dimensions)})\",\n",
    "    \"Einheiten\": getattr(variable_data, \"units\", \"N/A\"),\n",
    "    \"Langer Name\": getattr(variable_data, \"long_name\", \"N/A\"),\n",
    "}\n",
    "\n",
    "# Anzeigen der Zusammenfassung des Datensatzes als DataFrame zur besseren Visualisierung\n",
    "nc_summary = pd.DataFrame(list(summary.items()), columns=['Beschreibung', 'Bemerkungen'])\n",
    "\n",
    "# Anzeigen des Zusammenfassungs-DataFrames\n",
    "nc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drucken Sie eine Zusammenfassung aller Variablen des Datensatzes\n",
    "rows = []\n",
    "for variable in variables_list:\n",
    "    try:\n",
    "        var_obj = nc_dataset.variables[variable]\n",
    "        unit = getattr(var_obj, 'units', 'N/A')\n",
    "        shape = var_obj.shape\n",
    "        rows.append({\n",
    "            \"nc_variablen\": variable,\n",
    "            \"einheit\": unit,\n",
    "            \"form\": shape\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Verarbeitung der Variable {variable}: {e}\")\n",
    "\n",
    "# Erstelle ein DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd664fe",
   "metadata": {},
   "source": [
    "## 5. Exportieren der Zeitreihe im CSV-Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6844c20",
   "metadata": {},
   "source": [
    "### 5.1 Definieren Sie eine Funktion zur Berechnung des Tagesdurchschnitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a135acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Funktion zur Konvertierung von NetCDF-Daten in ein Pandas DataFrame\n",
    "def netcdf_to_dataframe(nc_file):\n",
    "    \"\"\"\n",
    "    Konvertiert eine NetCDF-Datei mit Daten zur Wassertemperatur der Seeoberfläche (LSWT)\n",
    "    in ein Pandas DataFrame mit berechneten Statistiken.\n",
    "\n",
    "    Parameter:\n",
    "    nc_file (str): Pfad zur NetCDF-Datei.\n",
    "\n",
    "    Rückgabe:\n",
    "    pd.DataFrame: Ein DataFrame mit Zeit, mittlerer Temperatur, Standardabweichung, \n",
    "                  Unsicherheit, mittlerer Qualitätsstufe und Anzahl der Nicht-Null-Pixel.\n",
    "    \"\"\"\n",
    "    # Öffne das NetCDF-Dataset im Lesemodus\n",
    "    with nc.Dataset(nc_file, \"r\") as nc_dataset:\n",
    "        # Extrahiere und dekodiere die Zeitvariable unter Berücksichtigung des Kalenders und der Einheiten\n",
    "        time_var = nc_dataset.variables[\"time\"]\n",
    "        time_units = time_var.units\n",
    "        time_calendar = getattr(time_var, \"calendar\", \"standard\")\n",
    "        cftime = nc.num2date(time_var[:], units=time_units, calendar=time_calendar)\n",
    "        datetime_cftime = [t.strftime(\"%Y-%m-%d %H:%M:%S\") for t in cftime]\n",
    "\n",
    "        # Extrahiere Temperaturdaten und zugehörige Einheiten\n",
    "        temperature_data = nc_dataset.variables[\"lake_surface_water_temperature\"][:]\n",
    "        temperature_data_units = nc_dataset.variables[\"lake_surface_water_temperature\"].units\n",
    "\n",
    "        # Berechne die mittlere Temperatur und die Standardabweichung für jeden Zeitschritt (gemittelt über die räumlichen Dimensionen)\n",
    "        temperature_mean_list = np.nanmean(temperature_data, axis=(1, 2))\n",
    "        temperature_std_list = np.nanstd(temperature_data, axis=(1, 2))\n",
    "        \n",
    "        # Zähle die Anzahl gültiger (nicht-NaN) Pixel für jeden Zeitschritt\n",
    "        nonzero_count_list = np.count_nonzero(~np.isnan(temperature_data), axis=(1,2))\n",
    "\n",
    "        # Extrahiere Unsicherheitsdaten und deren Einheiten\n",
    "        lswt_uncertainty = nc_dataset.variables[\"lswt_uncertainty\"][:]\n",
    "        lswt_uncertainty_units = nc_dataset.variables[\"lswt_uncertainty\"].units\n",
    "\n",
    "        # Berechne die Unsicherheit der mittleren Temperatur mittels der Quadratwurzel der gemittelten Unsicherheitsquadrate\n",
    "        lswt_uncertainty_squared = np.nanmean(lswt_uncertainty**2, axis=(1, 2))\n",
    "        lswt_mean_uncertainty = np.sqrt(lswt_uncertainty_squared)\n",
    "        \n",
    "        # Extrahiere und berechne den mittleren Qualitätswert für jeden Zeitschritt\n",
    "        lswt_quality_level = nc_dataset.variables[\"lswt_quality_level\"][:]\n",
    "        lswt_quality_level_mean_list = np.nanmean(lswt_quality_level, axis=(1, 2))\n",
    "\n",
    "        # Erstelle ein DataFrame mit den berechneten Statistiken\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"Time\": datetime_cftime,\n",
    "                f\"Mittlere Temperatur ({temperature_data_units[0].capitalize()})\": temperature_mean_list,\n",
    "                \"Standardabweichung\": temperature_std_list,\n",
    "                f\"Unsicherheit ({lswt_uncertainty_units[0].capitalize()})\": lswt_mean_uncertainty,\n",
    "                f\"Mittlere Qualitätsstufe\": lswt_quality_level_mean_list,\n",
    "                \"Nicht-Null-Anzahl\":nonzero_count_list,\n",
    "            }\n",
    "        )\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fe1a3",
   "metadata": {},
   "source": [
    "### 5.2 Erstellen des DataFrames für Jahresdaten und Export als CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ac465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definieren den CSV-Dateinamen und den Dateipfad für die Ausgabe\n",
    "csv_filename = f\"{dataset}_daily-mean_{year}.csv\"\n",
    "csv_filepath = os.path.join(csv_folder, csv_filename)\n",
    "\n",
    "# Exportieren das DataFrame als CSV, falls es noch nicht existiert\n",
    "if not os.path.isfile(csv_filepath):\n",
    "    dataframe = netcdf_to_dataframe(nc_filepath_merged)\n",
    "    filtered_dataframe = dataframe.dropna().reset_index(drop=True)\n",
    "\n",
    "    filtered_dataframe.to_csv(csv_filepath, sep=\",\", encoding='utf8', index=False)\n",
    "    print(f\"Gefilterte Daten erfolgreich exportiert nach {csv_filepath}\")\n",
    "else:\n",
    "    print(f\"Datei existiert bereits unter {csv_filepath}.\\nÜberspringen den Export.\")\n",
    "    print(\"Lesen bestehende CSV-Datei ein...\")\n",
    "    filtered_dataframe = pd.read_csv(csv_filepath)\n",
    "\n",
    "# Ändere die Pandas-Anzeigeoptionen\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Zeige das DataFrame an\n",
    "filtered_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67c307",
   "metadata": {},
   "source": [
    "## 6. Analyse und Visualisierung Optionen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056c789",
   "metadata": {},
   "source": [
    "### 6.1 Visualisierung des Tagesdurchschnitts mit Liniendiagramm\n",
    "\n",
    "> Hinweis: Aufgrund der begrenzten täglichen/monatlichen Daten für den Datensatz 2023 funktionieren **Plots** nicht richtig.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter, MonthLocator \n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "\n",
    "# Bereite das DataFrame für die Darstellung vor\n",
    "filtered_df = filtered_dataframe.copy()\n",
    "\n",
    "# Konvertiere 'Time' in das Datetime-Format und extrahiere sowie formatiere die 'Date'-Spalte\n",
    "filtered_df['Time'] = pd.to_datetime(filtered_df['Time'])\n",
    "filtered_df['Date'] = filtered_df['Time'].dt.date\n",
    "\n",
    "# Bestimme den Wertebereich für die y-Achse, gerundet auf die nächste Zehnerstelle\n",
    "vmax = math.ceil(filtered_df['Mittlere Temperatur (K)'].max() / 10) * 10\n",
    "vmin = math.floor(filtered_df['Mittlere Temperatur (K)'].min() / 10) * 10\n",
    "\n",
    "# Erstelle die Figur und Achsen\n",
    "fig, ax = plt.subplots(figsize=(12, 6), facecolor='#f1f1f1', edgecolor='k')\n",
    "\n",
    "# Plotten die mittlere Temperatur\n",
    "ax.plot(filtered_df['Date'],\n",
    "        filtered_df['Mittlere Temperatur (K)'],\n",
    "        marker='o',\n",
    "        markersize=4.5,\n",
    "        linestyle='--',\n",
    "        color='#1877F2',\n",
    "        label=\"Oberflächenwassertemperatur\",\n",
    "        )\n",
    "\n",
    "# Formatieren der x-Achse für bessere Lesbarkeit\n",
    "ax.xaxis.set_major_locator(MonthLocator())\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b'))\n",
    "ax.tick_params(axis='x', which='major', length=4, direction='inout', width=2)\n",
    "ax.tick_params(axis='x', which='minor', length=3, direction='inout')\n",
    "\n",
    "# Setzen der y-Achsen-Grenzen\n",
    "ax.set_ylim(vmin, vmax)\n",
    "\n",
    "# Setzen der Achsenbeschriftungen und Titel des Diagramms\n",
    "ax.set_xlabel('Monate', fontsize=12)\n",
    "ax.set_ylabel('Temperatur (K)', fontsize=12)\n",
    "ax.set_title(f'Oberflächenwassertemperatur des Bodensees, {year}', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Hinzufügen eines Rasters zum Diagramm und Formatierung der y-Achse\n",
    "ax.grid(visible=True, color='#b0b0b0', linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2f'))\n",
    "\n",
    "# Hinzufügen einer Beschreibung und Quelleninformation\n",
    "plt.figtext(\n",
    "    0.4,\n",
    "    -0.05,\n",
    "    (\n",
    "        'Beschreibung: Oberflächenwassertemperatur des Bodensees, ermittelt aus Satellitendaten des CDS.\\n'\n",
    "        'Quelle: Copernicus Climate Change Service, Climate Data Store, (2020): Oberflächenwassertemperatur von Seen '\n",
    "        'von 1995 bis heute, abgeleitet aus Satellitenbeobachtungen. Copernicus Climate Change Service (C3S) Climate Data Store (CDS). '\n",
    "        'DOI: 10.24381/cds.5714c668 (Zugriff am 22-01-2025)'\n",
    "    ),\n",
    "    ha='left',\n",
    "    va='center',\n",
    "    fontsize=9,\n",
    "    wrap=True,\n",
    "    backgroundcolor='w',\n",
    ")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# Layout anpassen und das Diagramm anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80848e",
   "metadata": {},
   "source": [
    "### 6.2 Visualisierung des monatlichen Durchschnitts mit Liniendiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereite das DataFrame für die Darstellung vor, indem monatliche Aggregation und Fehlerfortpflanzung durchgeführt werden\n",
    "\n",
    "# Gruppiere nach monatlichen Perioden anhand der 'Date'-Spalte\n",
    "filtered_df_monthly = (\n",
    "    filtered_df.groupby(pd.PeriodIndex(filtered_df[\"Date\"], freq=\"M\"))[[  \n",
    "        \"Mittlere Temperatur (K)\",  \n",
    "        \"Standardabweichung\",  \n",
    "        \"Unsicherheit (K)\",  \n",
    "        \"Mittlere Qualitätsstufe\"  \n",
    "    ]]  \n",
    "    .agg({  \n",
    "        \"Mittlere Temperatur (K)\": \"mean\",  \n",
    "        \"Standardabweichung\": lambda x: (x**2).mean()**0.5,  \n",
    "        \"Unsicherheit (K)\": lambda x: (x**2).mean()**0.5,  \n",
    "        \"Mittlere Qualitätsstufe\": \"mean\"  \n",
    "    })  \n",
    "    .reset_index()  \n",
    ")\n",
    "\n",
    "# Konvertiere den PeriodIndex zurück in Zeitstempel für eine konsistente Datumsverarbeitung\n",
    "filtered_df_monthly['Date'] = filtered_df_monthly['Date'].dt.to_timestamp()\n",
    "\n",
    "# Zeige das DataFrame an\n",
    "filtered_df_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f46c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle die Grafik und Achsen\n",
    "fig, ax = plt.subplots(figsize=(12, 6), facecolor='#f1f1f1', edgecolor='k')\n",
    "\n",
    "# Plotte die monatliche mittlere Temperatur mit Fehlerbalken\n",
    "ax.errorbar(\n",
    "    filtered_df_monthly['Date'],\n",
    "    filtered_df_monthly['Mittlere Temperatur (K)'],\n",
    "    yerr=filtered_df_monthly['Standardabweichung'],\n",
    "    fmt='o--',\n",
    "    label='Mittlere Temperatur ± Unsicherheit',\n",
    "    capsize=4,\n",
    "    elinewidth=1.5,\n",
    "    capthick=1.5,\n",
    ")\n",
    "\n",
    "# Formatieren der x-Achse für bessere Lesbarkeit\n",
    "ax.xaxis.set_major_locator(MonthLocator())\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b'))\n",
    "ax.tick_params(axis='x', which='major', length=4, direction='inout', width=2)\n",
    "ax.tick_params(axis='x', which='minor', length=3, direction='inout')\n",
    "\n",
    "# Setzen der y-Achsen-Grenzen\n",
    "ax.set_ylim(vmin, vmax)\n",
    "\n",
    "# Setzen der Achsenbeschriftungen und Titel des Diagramms\n",
    "ax.set_xlabel('Monate', fontsize=12)\n",
    "ax.set_ylabel('Temperatur (K)', fontsize=12)\n",
    "ax.set_title(f'Monatliche durchschnittliche Oberflächenwassertemperatur des Bodensees, {year}', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Hinzufügen eines Rasters zum Diagramm und Formatierung der y-Achse\n",
    "ax.grid(visible=True, color='#b0b0b0', linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2f'))\n",
    "\n",
    "# Hinzufügen einer Beschreibung und Quelleninformation\n",
    "plt.figtext(\n",
    "    0.4,\n",
    "    -0.05,\n",
    "    (\n",
    "        'Beschreibung: Oberflächenwassertemperatur des Bodensees, ermittelt aus Satellitendaten des CDS.\\n'\n",
    "        'Quelle: Copernicus Climate Change Service, Climate Data Store, (2020): Oberflächenwassertemperatur von Seen '\n",
    "        'von 1995 bis heute, abgeleitet aus Satellitenbeobachtungen. Copernicus Climate Change Service (C3S) Climate Data Store (CDS). '\n",
    "        'DOI: 10.24381/cds.5714c668 (Zugriff am 22-01-2025)'\n",
    "    ),\n",
    "    ha='left',\n",
    "    va='center',\n",
    "    fontsize=9,\n",
    "    wrap=True,\n",
    "    backgroundcolor='w',\n",
    ")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# Layout anpassen und das Diagramm anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98916fb7",
   "metadata": {},
   "source": [
    "### 6.3 Visualisierung des monatlichen Durchschnitts mit Balkendiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen die Figur und Achsen\n",
    "fig, ax = plt.subplots(figsize=(12, 6), facecolor='#f1f1f1', edgecolor='k')\n",
    "\n",
    "# Plotten die monatliche mittlere Temperatur als Balkendiagramm\n",
    "ax.bar(\n",
    "    filtered_df_monthly['Date'],\n",
    "    filtered_df_monthly['Mittlere Temperatur (K)'],\n",
    "    yerr=filtered_df_monthly['Standardabweichung'],\n",
    "    color='skyblue',\n",
    "    alpha=0.7,\n",
    "    width=25,\n",
    "    label='Mittlere Temperatur ± Unsicherheit',\n",
    "    capsize=5,\n",
    "    error_kw=dict(ecolor='black', lw=1.5),\n",
    ")\n",
    "\n",
    "# Formatieren der x-Achse für bessere Lesbarkeit\n",
    "ax.xaxis.set_major_locator(MonthLocator())\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b'))\n",
    "ax.tick_params(axis='x', which='major', length=4, direction='inout', width=2)\n",
    "ax.tick_params(axis='x', which='minor', length=3, direction='inout')\n",
    "\n",
    "# Setzen die Grenzen der y-Achse\n",
    "ax.set_ylim(vmin, vmax)\n",
    "\n",
    "# Setzen der Achsenbeschriftungen und Titel des Diagramms\n",
    "ax.set_xlabel('Monate', fontsize=12)\n",
    "ax.set_ylabel('Temperatur (K)', fontsize=12)\n",
    "ax.set_title(f'Monatliche durchschnittliche Oberflächenwassertemperatur des Bodensees, {year}', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Hinzufügen eines Rasters zum Diagramm und Formatierung der y-Achse\n",
    "ax.grid(visible=True, color='#b0b0b0', linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2f'))\n",
    "\n",
    "# Hinzufügen einer Beschreibung und Quelleninformation\n",
    "plt.figtext(\n",
    "    0.4,\n",
    "    -0.05,\n",
    "    (\n",
    "        'Beschreibung: Oberflächenwassertemperatur des Bodensees, ermittelt aus Satellitendaten des CDS.\\n'\n",
    "        'Quelle: Copernicus Climate Change Service, Climate Data Store, (2020): Oberflächenwassertemperatur von Seen '\n",
    "        'von 1995 bis heute, abgeleitet aus Satellitenbeobachtungen. Copernicus Climate Change Service (C3S) Climate Data Store (CDS). '\n",
    "        'DOI: 10.24381/cds.5714c668 (Zugriff am 22-01-2025)'\n",
    "    ),\n",
    "    ha='left',\n",
    "    va='center',\n",
    "    fontsize=9,\n",
    "    wrap=True,\n",
    "    backgroundcolor='w',\n",
    ")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# Layout anpassen und das Diagramm anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e72a5",
   "metadata": {},
   "source": [
    "## 7. Exportieren der NetCDF4-Datei nach GeoTIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5188f58",
   "metadata": {},
   "source": [
    "### 7.1 Exportieren Sie den jährlichen Datensatz als eine GeoTIFF-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio  \n",
    "from rasterio.transform import from_origin  \n",
    "import netCDF4 as nc  \n",
    "from tqdm.notebook import tqdm  \n",
    "\n",
    "def main_export_geotiff(nc_file):  \n",
    "    # NetCDF-Datei öffnen und Variable auslesen  \n",
    "    nc_dataset = nc.Dataset(nc_file, mode='r')  \n",
    "    temperature_data = nc_dataset[variable_name]  \n",
    "\n",
    "    # Zeitvariable extrahieren und in ein lesbares Datumsformat konvertieren  \n",
    "    time_var = nc_dataset.variables['time']  \n",
    "    time_units = nc_dataset.variables['time'].units  \n",
    "    time_calendar = getattr(time_var, \"calendar\", \"standard\")  \n",
    "    cftime = nc.num2date(time_var[:], units=time_units, calendar=time_calendar)  \n",
    "\n",
    "    # Räumliche Auflösung berechnen und Rastertransformation definieren  \n",
    "    lat = nc_dataset['lat'][:]  \n",
    "    lon = nc_dataset['lon'][:]  \n",
    "\n",
    "    pixelgröße_lat = (lat.max() - lat.min()) / (len(lat) - 1)  \n",
    "    pixelgröße_lon = (lon.max() - lon.min()) / (len(lon) - 1)  \n",
    "    transform = from_origin(lon.min() - pixelgröße_lon / 2,  \n",
    "                            lat.min() - pixelgröße_lat / 2,  \n",
    "                            pixelgröße_lon,  \n",
    "                            -pixelgröße_lat  \n",
    "                            )  \n",
    "\n",
    "    # Ausgabepfad für das zusammengeführte GeoTIFF definieren  \n",
    "    output_filename = f\"{variable_name}_{year}_merged.tif\"  \n",
    "    output_folder = os.path.join(geotiff_folder, \"merged_geotiff\")  \n",
    "    os.makedirs(output_folder, exist_ok=True)  \n",
    "    output_filepath = os.path.join(output_folder, output_filename)  \n",
    "\n",
    "    if not os.path.isfile(output_filepath):  \n",
    "        # GeoTIFF-Datei mit mehreren Bändern (je eines pro Zeitschritt) erstellen  \n",
    "        with rasterio.open(  \n",
    "            output_filepath,  \n",
    "            \"w\",  \n",
    "            driver=\"GTiff\",  \n",
    "            dtype=str(temperature_data.dtype),  \n",
    "            width=temperature_data.shape[2],  \n",
    "            height=temperature_data.shape[1],  \n",
    "            count=temperature_data.shape[0],  \n",
    "            crs=\"EPSG:4326\",  \n",
    "            nodata=-9999,  \n",
    "            transform=transform,        \n",
    "        ) as dst:  \n",
    "            # Jeden Zeitschritt als separates Band schreiben  \n",
    "            for day_index in tqdm(range(temperature_data.shape[0]),  \n",
    "                                  desc=f\"Zusammengeführte GeoTIFF-Datei für {year} exportieren\"):  \n",
    "                band_data = temperature_data[day_index, :, :]  \n",
    "                dt = cftime[day_index]  \n",
    "                band_desc = f\"{dt.year:04d}-{dt.month:02d}-{dt.day:02d}\"  \n",
    "\n",
    "                # Daten für das aktuelle Band schreiben und Band annotieren  \n",
    "                dst.write(band_data, day_index + 1)  \n",
    "                dst.set_band_description(day_index + 1, band_desc)  \n",
    "    else:  \n",
    "        print(f\"'{output_filename}' existiert bereits. Export überspringen.\")  \n",
    "\n",
    "# Parameter für die Verarbeitung der NetCDF-Datei definieren  \n",
    "nc_filename = f\"{dataset}_{year}.nc\"  \n",
    "nc_filepath_merged = os.path.join(output_folder, nc_filename)  \n",
    "variable_name = 'lake_surface_water_temperature'  \n",
    "\n",
    "# Exportprozess ausführen  \n",
    "main_export_geotiff(nc_filepath_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8b5ed",
   "metadata": {},
   "source": [
    "### 7.2 Export des Jahresdatensatzes als einzelne GeoTIFF-Dateien  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc21670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio  \n",
    "from rasterio.transform import from_origin  \n",
    "import netCDF4 as nc  \n",
    "from tqdm.notebook import tqdm  \n",
    "\n",
    "def main_export_individual_geotiff(nc_file):  \n",
    "    # NetCDF-Datensatz öffnen und Variablendaten auslesen  \n",
    "    nc_dataset = nc.Dataset(nc_file, mode='r')  \n",
    "    temperature_data = nc_dataset[variable_name]  \n",
    "\n",
    "    # Zeitvariable extrahieren und in ein lesbares Datumsformat konvertieren  \n",
    "    time_var = nc_dataset.variables['time']  \n",
    "    time_units = nc_dataset.variables['time'].units  \n",
    "    time_calendar = getattr(time_var, \"calendar\", \"standard\")  \n",
    "    cftime = nc.num2date(time_var[:], units=time_units, calendar=time_calendar)  \n",
    "\n",
    "    # Räumliche Auflösung berechnen und Rastertransformation definieren  \n",
    "    lat = nc_dataset['lat'][:]  \n",
    "    lon = nc_dataset['lon'][:]  \n",
    "\n",
    "    pixelgröße_lat = (lat.max() - lat.min()) / (len(lat) - 1)  \n",
    "    pixelgröße_lon = (lon.max() - lon.min()) / (len(lon) - 1)  \n",
    "    transform = from_origin(lon.min() - pixelgröße_lon / 2,  \n",
    "                            lat.min() - pixelgröße_lat / 2,  \n",
    "                            pixelgröße_lon,  \n",
    "                            -pixelgröße_lat  \n",
    "                            )  \n",
    "\n",
    "    # Ausgabeordner für einzelne GeoTIFF-Dateien des ausgewählten Jahres definieren und erstellen  \n",
    "    year_folder = os.path.join(geotiff_folder, f\"{year}_individual_geotiff\")  \n",
    "    os.makedirs(year_folder, exist_ok=True)  \n",
    "\n",
    "    if len(os.listdir(year_folder)) == 0:  \n",
    "        # Einzelne GeoTIFF-Dateien mit täglichen Zeitschritten erstellen  \n",
    "        for day_index in tqdm(range(temperature_data.shape[0]), desc=f\"GeoTIFF-Dateien für {year} exportieren\"):  \n",
    "            dt = cftime[day_index]  \n",
    "            band_desc = f\"{dt.year:04d}-{dt.month:02d}-{dt.day:02d}\"  \n",
    "\n",
    "            output_filename = f\"{variable_name}_{band_desc}.tif\"  \n",
    "            output_filepath = os.path.join(year_folder, output_filename)  \n",
    "\n",
    "            band_data = temperature_data[day_index, :, :]  \n",
    "\n",
    "            # GeoTIFF-Datei mit einem einzelnen Band für jeden Zeitschritt erstellen  \n",
    "            with rasterio.open(  \n",
    "                output_filepath,  \n",
    "                \"w\",  \n",
    "                driver=\"GTiff\",  \n",
    "                dtype=str(band_data.dtype),  \n",
    "                width=band_data.shape[1],  \n",
    "                height=band_data.shape[0],  \n",
    "                count=1,  \n",
    "                crs=\"EPSG:4326\",  \n",
    "                nodata=-9999,  \n",
    "                transform=transform,        \n",
    "            ) as dst:  \n",
    "                # Daten für das aktuelle Band schreiben und Band annotieren  \n",
    "                dst.write(band_data, 1)  \n",
    "                dst.set_band_description(1, band_desc)  \n",
    "    else:  \n",
    "        print(f\"Ordner ist nicht leer. Export überspringen.\")  \n",
    "\n",
    "# Parameter für die Verarbeitung der NetCDF-Datei definieren  \n",
    "nc_filename_merged = f\"{dataset}_{year}.nc\"  \n",
    "nc_filepath_merged = os.path.join(output_folder, nc_filename)  \n",
    "variable_name = 'lake_surface_water_temperature'  \n",
    "\n",
    "# Exportprozess ausführen  \n",
    "main_export_individual_geotiff(nc_filepath_merged)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f069558",
   "metadata": {},
   "source": [
    "## 8. Zusätzliche Visualisierung mit einem Kalenderdiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bdccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  \n",
    "import pandas as pd  \n",
    "\n",
    "# Funktion definieren, um Metadaten aus einem NetCDF-Dateinamen zu extrahieren  \n",
    "def meta(filename):  \n",
    "    match = re.search(r\"(.+?)_(\\d{4})\\.nc\", filename)  \n",
    "    if not match:  \n",
    "        raise ValueError(\"Der angegebene Dateiname entspricht nicht dem erwarteten Namensschema.\")  \n",
    "\n",
    "    def get_nc_variable():  \n",
    "        with nc.Dataset(os.path.join(output_folder, filename), 'r') as nc_dataset:  \n",
    "            nc_variable_name_list = nc_dataset.variables.keys()  \n",
    "\n",
    "            primary_variable_index = 0  \n",
    "            primary_variable = [*nc_variable_name_list][primary_variable_index]  \n",
    "            primary_variable_shape = np.shape(nc_dataset[primary_variable])  \n",
    "\n",
    "            return primary_variable, primary_variable_shape  \n",
    "\n",
    "    # Metadaten als Dictionary zurückgeben  \n",
    "    return dict(  \n",
    "        filename=filename,  \n",
    "        path=os.path.join(output_folder, filename),  \n",
    "        year=match.group(2),  \n",
    "        variable_name=get_nc_variable()[0],  \n",
    "        variable_shape=get_nc_variable()[1],  \n",
    "    )  \n",
    "\n",
    "# Alle NetCDF-Dateien im Ausgabeordner auflisten, verarbeiten und nach Jahr sortieren  \n",
    "nc_files = [meta(f) for f in os.listdir(output_folder) if f.endswith('.nc')]  \n",
    "nc_files = sorted(nc_files, key=lambda x: x['year'])  \n",
    "\n",
    "df_nc_files = pd.DataFrame.from_dict(nc_files)  \n",
    "\n",
    "# DataFrame anzeigen, ohne den Pfad anzuzeigen  \n",
    "df_nc_files.head().loc[:, df_nc_files.columns != 'path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9294b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr  \n",
    "import calmap  \n",
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd  \n",
    "import math as ma  \n",
    "\n",
    "def plot_calendarplot(year=None):  \n",
    "    # NetCDF-Datei für das angegebene Jahr filtern  \n",
    "    nc_file = next((item for item in nc_files if item['year'] == str(year)), None)  \n",
    "\n",
    "    if not nc_file:  \n",
    "        print(f\"Keine NetCDF-Datei für das angegebene Jahr gefunden.\")  \n",
    "        print(\"Das neueste verfügbare Jahr wird ausgewählt.\")  \n",
    "        if nc_files:  \n",
    "            nc_file = nc_files[-1]  # Das neueste verfügbare Jahr auswählen  \n",
    "            print(f\"Es werden Daten aus dem Jahr {nc_file['year']} verwendet.\")  \n",
    "        else:  \n",
    "            print(\"Keine NetCDF-Dateien verfügbar.\")  \n",
    "            return  \n",
    "\n",
    "    # Die NetCDF-Datei öffnen und die angegebene Variable verarbeiten  \n",
    "    with xr.open_dataset(nc_file['path']) as nc_dataset:  \n",
    "        # Variablendaten als DataFrame extrahieren  \n",
    "        variable_data = nc_dataset[nc_file['variable_name']]  \n",
    "        df = variable_data.to_dataframe().reset_index().dropna().reset_index(drop=True)  \n",
    "\n",
    "        # 'time' in das Datetime-Format konvertieren und 'day_of_year' sowie 'date' ableiten  \n",
    "        df['time'] = pd.to_datetime(df['time'])  \n",
    "        df['day_of_year'] = df['time'].dt.dayofyear  \n",
    "        df['date'] = df['time'].dt.year.astype(str) + '-' + df['day_of_year'].astype(str).str.zfill(3)  \n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y-%j').dt.strftime('%Y-%m-%d')  \n",
    "\n",
    "        # Nach 'date' gruppieren und den täglichen Mittelwert für die Variable berechnen  \n",
    "        df2 = df.groupby('date')[variable_name].mean()  \n",
    "\n",
    "    # Sicherstellen, dass der Index des Ergebnisses ein datetime-Format hat  \n",
    "    df2.index = pd.to_datetime(df2.index)  \n",
    "\n",
    "    # Kalender-Heatmap der mittleren Temperaturwerte plotten  \n",
    "    fig, axs = calmap.calendarplot(df2,  \n",
    "                                fig_kws={'figsize': (12, 8)},  \n",
    "                                yearlabel_kws={'color': 'black', 'fontsize': 22},  \n",
    "                                subplot_kws={'title': f'Kalender-Heatmap von {variable_name} für {year}'},  \n",
    "                                cmap='YlGnBu',  \n",
    "                                fillcolor='#efefef',  \n",
    "                                daylabels='MTWTFSS',  \n",
    "                                linecolor='#ffffff',  \n",
    "                                dayticks=True,  \n",
    "                                )  \n",
    "\n",
    "    # Farbleiste rechts neben dem Diagramm hinzufügen  \n",
    "    cax = fig.add_axes([1.005, 0.38, 0.02, 0.2])  \n",
    "    vmin = ma.floor(df2.min() // 5 * 5)  \n",
    "    vmax = ma.ceil(df2.max() // 5 * 5)  \n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap='YlGnBu', norm=plt.Normalize(vmin=vmin, vmax=vmax))  \n",
    "    cbar = fig.colorbar(sm, cax=cax)  \n",
    "\n",
    "    # Ticks auf der Farbleiste anpassen  \n",
    "    tick_interval = 5  \n",
    "    ticks = np.arange(vmin, vmax + 1, tick_interval)  \n",
    "    cbar.set_ticks(ticks)  # Ticks setzen  \n",
    "    cbar.set_ticklabels(ticks)  \n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    # Kalender-Heatmap für das angegebene Jahr plotten  \n",
    "    plot_calendarplot(year=1990)  \n",
    "    plot_calendarplot(year=2005)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
