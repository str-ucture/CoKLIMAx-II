{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8c8af7",
   "metadata": {},
   "source": [
    "# Heat Wave and Cold Spells\n",
    "\n",
    "Dieses Skript verarbeitet den Datensatz \"Heat Wave Days\" aus dem Copernics Climate Data Store. Der Datensatz enthält die Anzahl der Hitzewellen-Tage (Heat wave days; HWD), die mit verschiedenen europaweiten sowie nationalen/regionalen Definitionen im Rahmen des C3S European Health Service entwickelt wurden. Diese Tage sind für unterschiedliche zukünftige Zeiträume und Klimawandelszenarien verfügbar.\n",
    "\n",
    "**Informationen zum Datensatz**: \n",
    "\n",
    "* Source: [Heat Wave and Cold Spells](https://cds.climate.copernicus.eu/datasets/sis-heat-and-cold-spells?tab=overview)\n",
    "* Author: T. Tewes (Stadt Konstanz) \n",
    "* Notebook-Version: 1.2 (Aktualisiert: März 05, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ac21f",
   "metadata": {},
   "source": [
    "## 1. Festlegen der Pfade und Arbeitsverzeichnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c748dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' ---- Verzeichnisse hier angeben ---- '''\n",
    "download_folder = r\".\\data\\sis-heat-and-cold-spells\\download\"\n",
    "working_folder = r\".\\data\\sis-heat-and-cold-spells\\working\"\n",
    "geotiff_folder = r\".\\data\\sis-heat-and-cold-spells\\geotiff\"\n",
    "csv_folder = r\".\\data\\sis-heat-and-cold-spells\\csv\"\n",
    "output_folder = r\".\\data\\sis-heat-and-cold-spells\\output\"\n",
    "''' ----- Ende der Angaben ---- '''\n",
    "\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "os.makedirs(working_folder, exist_ok=True)\n",
    "os.makedirs(geotiff_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce50101",
   "metadata": {},
   "source": [
    "## 2. Herunterladen und Entpacken des Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16866554",
   "metadata": {},
   "source": [
    "### 2.1 Authentifizierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1303d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "def main():\n",
    "    # API-Key für die Authentifizierung\n",
    "    api_key = \"fdae60fd-35d4-436f-825c-c63fedab94a4\"\n",
    "    api_url = \"https://cds.climate.copernicus.eu/api\"\n",
    "\n",
    "    # Erstellung des CDS-API-Clients\n",
    "    client = cdsapi.Client(url=api_url, key=api_key)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c07e8",
   "metadata": {},
   "source": [
    "### 2.2 Definieren Sie die „request“ und laden Sie den Datensatz herunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9520c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren der Begrenzungsrahmen-Koordinaten (WGS84-Format)\n",
    "# Das Koordinatenformat lautet: [Norden, Westen, Süden, Osten]\n",
    "bbox_wgs84_deutschland = [56.0, 5.8, 47.2, 15.0]\n",
    "bbox_wgs84_konstanz = [47.9, 8.9, 47.6, 9.3]\n",
    "bbox_wgs84_konstanz_standard = [9.0, 47.6, 9.3, 47.8]  # [West, South, East, North]\n",
    "\n",
    "# Alternativ können Sie ein Shapefile für eine präzise geografische Filterung verwenden\n",
    "import geopandas as gpd\n",
    "import math\n",
    "\n",
    "# Beispiel: Shapefile von Konstanz laden (WGS84-Projektion)\n",
    "de_shapefile = r\"./shapefiles/de_boundary.shp\"\n",
    "de_gdf = gpd.read_file(de_shapefile)\n",
    "\n",
    "# Extrahieren Sie den Begrenzungsrahmen des Shapefiles\n",
    "de_bounds = de_gdf.total_bounds\n",
    "\n",
    "# Passen Sie den Begrenzungsrahmen an und puffern Sie ihn, um einen etwas größeren\n",
    "de_bounds_adjusted = [(math.floor(de_bounds[0]* 10)/10)-0.1,\n",
    "                      (math.floor(de_bounds[1]* 10)/10)-0.1,\n",
    "                      (math.ceil(de_bounds[2]* 10)/10)+0.1,\n",
    "                      (math.ceil(de_bounds[3]* 10)/10)+0.1]\n",
    "\n",
    "# Ordnen Sie die Koordinaten in das Format: [Nord, West, Süd, Ost] um.\n",
    "bbox_de_bounds_adjusted = [de_bounds_adjusted[3], de_bounds_adjusted[0],\n",
    "                           de_bounds_adjusted[1], de_bounds_adjusted[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ausgewählte_variable: heat_wave_days\n",
      "ausgewählte_definition: ['climatological_related', 'health_related', 'country_related']\n"
     ]
    }
   ],
   "source": [
    "# Der Datensatz sis-heat-and-cold-spells ermöglicht die Auswahl zwischen zwei Variablen:\n",
    "# \"Heat wave days\" and \"Cold spell days\".\n",
    "# Abhängig von der gewählten Variablen variieren die Definitionsoptionen.\n",
    "# Für \"heat_wave_days\" sind alle Definitionen verfügbar.\n",
    "# Für \"cold_spell_days\" wird nur die 'landesspezifische' Definition unterstützt.\n",
    "\n",
    "variable_to_definition_map = {\n",
    "    'heat_wave_days': ['climatological_related', 'health_related', 'country_related'],\n",
    "    'cold_spell_days': ['country_related']\n",
    "}\n",
    "\n",
    "# Ausgewählte Variable\n",
    "selected_variable = 'heat_wave_days'\n",
    "\n",
    "# Abrufen der entsprechenden Definitionen basierend auf der ausgewählten Variablen\n",
    "selected_definition = variable_to_definition_map.get(selected_variable, [])\n",
    "\n",
    "# Ausgabe der ausgewählten Definitionen und der Variable\n",
    "print(f\"ausgewählte_variable: {selected_variable}\\nausgewählte_definition: {selected_definition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc970752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Datensatzes und der Request-Parameter\n",
    "dataset = \"sis-heat-and-cold-spells\"\n",
    "request = {\n",
    "    \"variable\": selected_variable,\n",
    "    \"definition\": selected_definition,\n",
    "    \"experiment\": [\n",
    "        \"rcp4_5\",\n",
    "        \"rcp8_5\"\n",
    "    ],\n",
    "    \"ensemble_statistic\": [\n",
    "        \"ensemble_members_average\",\n",
    "        \"ensemble_members_standard_deviation\"\n",
    "    ],\n",
    "    \"area\": bbox_de_bounds_adjusted\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensatz bereits heruntergeladen.\n"
     ]
    }
   ],
   "source": [
    "# Führen Sie es aus, um den Datensatz herunterzuladen:\n",
    "def main_retrieve():\n",
    "    dataset_filename = f\"{dataset}-{selected_definition}.zip\"\n",
    "    dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "\n",
    "    # Den Datensatz nur herunterladen, wenn er noch nicht heruntergeladen wurde\n",
    "    if not os.path.isfile(dataset_filepath):\n",
    "        # Rufen Sie den CDS-Client nur auf, wenn der Datensatz noch nicht heruntergeladen wurde.\n",
    "        client = main()\n",
    "        # Den Datensatz mit den definierten Anforderungsparametern herunterladen\n",
    "        client.retrieve(dataset, request, dataset_filepath)\n",
    "    else:\n",
    "        print(\"Datensatz bereits heruntergeladen.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extrahieren die ZIP-Datei in Ordner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordner ist nicht leer. Entpacken überspringen.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Definieren Sie einen Extraktionsordner für die ZIP-Datei, der dem Arbeitsordner entspricht\n",
    "extract_folder = os.path.join(working_folder, f\"{selected_variable}\")\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "try:\n",
    "    if not os.listdir(extract_folder):\n",
    "        dataset_filename = f\"{dataset}-{selected_definition}.zip\"\n",
    "        dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "        \n",
    "        with zipfile.ZipFile(dataset_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_folder)\n",
    "            print(f\"Dateien erfolgreich extrahiert nach: {extract_folder}\")\n",
    "    else:\n",
    "        print(\"Ordner ist nicht leer. Entpacken überspringen.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Fehler: Die Datei {dataset_filepath} wurde nicht gefunden.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(f\"Fehler: Die Datei {dataset_filepath} ist keine gültige ZIP-Datei.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ein unerwarteter Fehler ist aufgetreten: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Untersuchen der Metadaten der NetCDF4-Datei\n",
    "\n",
    "⚠️ <span style=\"background-color: red; color: white; padding: 2px 4px;\">Wichtig</span>: Obwohl alle Datensätze zum Download verfügbar sind, konzentriert sich dieses Notebook auf die Analyse der folgenden Auswahl:\n",
    "* selected_variable = 'heat_wave_days'\n",
    "* selected_definition = 'climatological related'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable und Definition definieren\n",
    "selected_variable = 'heat_wave_days'\n",
    "selected_definition = 'climatological_related'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Erstellen eines DataFrame mit verfügbaren NetCDF-Dateien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ds_variable</th>\n",
       "      <th>ds_definition</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>rcp</th>\n",
       "      <th>rcp_statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HWD_EU_climate_rcp45...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>EU_climate</td>\n",
       "      <td>HWD_EU_climate</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HWD_EU_climate_rcp45...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>EU_climate</td>\n",
       "      <td>HWD_EU_climate</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>stdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HWD_EU_climate_rcp85...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>EU_climate</td>\n",
       "      <td>HWD_EU_climate</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HWD_EU_climate_rcp85...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>EU_climate</td>\n",
       "      <td>HWD_EU_climate</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>stdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HWD_EU_health_rcp45_...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>EU_health</td>\n",
       "      <td>HWD_EU_health</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HWD_EU_health_rcp45_...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>EU_health</td>\n",
       "      <td>HWD_EU_health</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>stdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HWD_EU_health_rcp85_...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>EU_health</td>\n",
       "      <td>HWD_EU_health</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HWD_EU_health_rcp85_...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>EU_health</td>\n",
       "      <td>HWD_EU_health</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>stdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HWD_national_rcp45_m...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>national</td>\n",
       "      <td>HWD_merged</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HWD_national_rcp45_s...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>national</td>\n",
       "      <td>HWD_merged</td>\n",
       "      <td>rcp45</td>\n",
       "      <td>stdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HWD_national_rcp85_m...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>national</td>\n",
       "      <td>HWD_merged</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HWD_national_rcp85_s...</td>\n",
       "      <td>HWD</td>\n",
       "      <td>national</td>\n",
       "      <td>HWD_merged</td>\n",
       "      <td>rcp85</td>\n",
       "      <td>stdev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename ds_variable ds_definition   variable_name    rcp  \\\n",
       "0   HWD_EU_climate_rcp45...         HWD    EU_climate  HWD_EU_climate  rcp45   \n",
       "1   HWD_EU_climate_rcp45...         HWD    EU_climate  HWD_EU_climate  rcp45   \n",
       "2   HWD_EU_climate_rcp85...         HWD    EU_climate  HWD_EU_climate  rcp85   \n",
       "3   HWD_EU_climate_rcp85...         HWD    EU_climate  HWD_EU_climate  rcp85   \n",
       "4   HWD_EU_health_rcp45_...         HWD     EU_health   HWD_EU_health  rcp45   \n",
       "5   HWD_EU_health_rcp45_...         HWD     EU_health   HWD_EU_health  rcp45   \n",
       "6   HWD_EU_health_rcp85_...         HWD     EU_health   HWD_EU_health  rcp85   \n",
       "7   HWD_EU_health_rcp85_...         HWD     EU_health   HWD_EU_health  rcp85   \n",
       "8   HWD_national_rcp45_m...         HWD      national      HWD_merged  rcp45   \n",
       "9   HWD_national_rcp45_s...         HWD      national      HWD_merged  rcp45   \n",
       "10  HWD_national_rcp85_m...         HWD      national      HWD_merged  rcp85   \n",
       "11  HWD_national_rcp85_s...         HWD      national      HWD_merged  rcp85   \n",
       "\n",
       "   rcp_statistic  \n",
       "0           mean  \n",
       "1          stdev  \n",
       "2           mean  \n",
       "3          stdev  \n",
       "4           mean  \n",
       "5          stdev  \n",
       "6           mean  \n",
       "7          stdev  \n",
       "8           mean  \n",
       "9          stdev  \n",
       "10          mean  \n",
       "11         stdev  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "\n",
    "def meta(filename):\n",
    "    # Überprüfen, ob der Dateiname dem erwarteten Muster entspricht\n",
    "    match = re.search(r\"(?P<ds_variable>\\w+?)_(?P<ds_definition>\\w+?)_(?P<rcp>rcp\\d+?)_(?P<rcp_statistic>mean|stdev)_v(\\d+\\.\\d+)\\.\", filename)\n",
    "    \n",
    "    # Fehler ausgeben, wenn der Dateiname nicht dem erwarteten Schema entspricht\n",
    "    if not match:\n",
    "        match = re.search(\"Der angegebene Dateiname entspricht nicht dem erwarteten Benennungsschema.\")\n",
    "    \n",
    "    # Funktion zum Extrahieren des Variablennamens aus der NetCDF-Datei\n",
    "    def get_nc_variable():\n",
    "        with nc.Dataset(os.path.join(extract_folder, filename), 'r') as nc_dataset:\n",
    "            nc_variable_name = nc_dataset.variables.keys()\n",
    "            return [*nc_variable_name][0]\n",
    "    \n",
    "    # Metadaten als Dictionary zurückgeben\n",
    "    return dict(\n",
    "        filename=filename,\n",
    "        path=os.path.join(extract_folder, filename),\n",
    "        ds_variable=match.group('ds_variable'),\n",
    "        ds_definition=match.group('ds_definition'),\n",
    "        variable_name=get_nc_variable(),\n",
    "        rcp=match.group('rcp'),\n",
    "        rcp_statistic=match.group('rcp_statistic')\n",
    "    )\n",
    "\n",
    "# Metadaten für alle NetCDF-Dateien im Ordner extrahieren\n",
    "# Das Dictionary 'nc_files' enthält alle relevanten Metadaten der verfügbaren NetCDF4-Dateien\n",
    "# Dieses Dictionary wird später verwendet, um die Dateien in GeoTiff zu konvertieren\n",
    "nc_files = [meta(f) for f in os.listdir(extract_folder) if f.endswith('.nc')]\n",
    "df_nc_files = pd.DataFrame.from_dict(nc_files)\n",
    "\n",
    "# Pandas-Anzeigeoptionen anpassen\n",
    "pd.options.display.max_colwidth = 24\n",
    "\n",
    "# DataFrame anzeigen, ohne die Spalte 'path' darzustellen\n",
    "df_nc_files.loc[:, df_nc_files.columns != 'path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Einzigartige Variablennamen und verfügbare Variablen ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  HWD_EU_climate    : Verfügbare Variablen: ['HWD_EU_climate', 'height', 'quantile', 'lat', 'lon', 'time']\n",
      "5  HWD_EU_health     : Verfügbare Variablen: ['HWD_EU_health', 'height', 'lat', 'lon', 'time']\n",
      "9  HWD_merged        : Verfügbare Variablen: ['HWD_merged', 'height', 'lat', 'lon', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Variable definieren, um bereits verarbeitete Variablennamen zu speichern und Duplikate zu vermeiden  \n",
    "seen_variables = set()\n",
    "\n",
    "# Alle Variablen in jeder NetCDF-Datei auflisten  \n",
    "for i, nc_file in enumerate(nc_files):\n",
    "    variable_name = nc_file['variable_name']\n",
    "    \n",
    "    # Überspringen, wenn die Variable bereits verarbeitet wurde  \n",
    "    if variable_name in seen_variables:\n",
    "        continue\n",
    "\n",
    "    # NetCDF-Datei im Lesemodus öffnen  \n",
    "    with nc.Dataset(nc_file['path'], mode='r') as nc_dataset:  \n",
    "        # Alle Variablen im aktuellen Datensatz auflisten  \n",
    "        variables_list = list(nc_dataset.variables.keys())  \n",
    "        \n",
    "        # Details der Datei und ihrer Variablen ausgeben  \n",
    "        print(f\"{i + 1:<2} {variable_name:<18}: Verfügbare Variablen: {variables_list}\") \n",
    "    \n",
    "    # Diese Variable als verarbeitet markieren  \n",
    "    seen_variables.add(variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Zusammenfassung der Variable 'HWD_EU_climate':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Bemerkungen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Variablenname</td>\n",
       "      <td>HWD_EU_climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datentyp</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Form</td>\n",
       "      <td>(100, 82, 95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variableninfo</td>\n",
       "      <td>('time', 'lat', 'lon')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Einheiten</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Langer Name</td>\n",
       "      <td>Ensemble members ave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Beschreibung              Bemerkungen\n",
       "0  Variablenname           HWD_EU_climate\n",
       "1       Datentyp                  float32\n",
       "2           Form            (100, 82, 95)\n",
       "3  Variableninfo   ('time', 'lat', 'lon')\n",
       "4      Einheiten                      day\n",
       "5    Langer Name  Ensemble members ave..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Zusammenfassung der Variable 'HWD_EU_health':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Bemerkungen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Variablenname</td>\n",
       "      <td>HWD_EU_health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datentyp</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Form</td>\n",
       "      <td>(100, 82, 95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variableninfo</td>\n",
       "      <td>('time', 'lat', 'lon')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Einheiten</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Langer Name</td>\n",
       "      <td>Ensemble members ave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Beschreibung              Bemerkungen\n",
       "0  Variablenname            HWD_EU_health\n",
       "1       Datentyp                  float32\n",
       "2           Form            (100, 82, 95)\n",
       "3  Variableninfo   ('time', 'lat', 'lon')\n",
       "4      Einheiten                      day\n",
       "5    Langer Name  Ensemble members ave..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... (Ausgabe auf die ersten 2 Variablen gekürzt)\n"
     ]
    }
   ],
   "source": [
    "# Alle Variableninformationen in jeder NetCDF-Datei auflisten  \n",
    "seen_variables = set()\n",
    "\n",
    "# Alle variablen Informationen in jeder NetCDF-Datei auflisten\n",
    "for i, nc_file in enumerate(nc_files):\n",
    "    variable_name = nc_file['variable_name']\n",
    "    \n",
    "    # Überspringen, wenn die Variable bereits verarbeitet wurde\n",
    "    if variable_name in seen_variables:\n",
    "        continue\n",
    "    \n",
    "    # NetCDF-Datei im Lesemodus öffnen\n",
    "    with nc.Dataset(nc_file['path'], mode='r') as nc_dataset:  \n",
    "        # Primärvariable-Daten abrufen  \n",
    "        variable_data = nc_dataset[variable_name]  \n",
    "\n",
    "        # Zusammenfassung der Primärvariable erstellen  \n",
    "        summary = {  \n",
    "            \"Variablenname\": variable_name,  \n",
    "            \"Datentyp\": variable_data.dtype,  \n",
    "            \"Form\": variable_data.shape,  \n",
    "            \"Variableninfo\": f\"{variable_data.dimensions}\",  \n",
    "            \"Einheiten\": getattr(variable_data, \"units\", \"N/A\"),  \n",
    "            \"Langer Name\": getattr(variable_data, \"long_name\", \"N/A\"),  \n",
    "        }  \n",
    "\n",
    "        # Datensatz-Zusammenfassung als DataFrame zur besseren Visualisierung anzeigen  \n",
    "        nc_summary = pd.DataFrame(list(summary.items()), columns=['Beschreibung', 'Bemerkungen'])  \n",
    "        print(f\"{i + 1}. Zusammenfassung der Variable '{variable_name}':\")  \n",
    "        display(nc_summary)  \n",
    "\n",
    "    # Variablenname zur Liste der bereits verarbeiteten Variablen hinzufügen  \n",
    "    seen_variables.add(variable_name)  \n",
    "\n",
    "    # Ausgabe begrenzen  \n",
    "    output_limit = 2  \n",
    "    if len(seen_variables) >= output_limit:  \n",
    "        print(f\".... (Ausgabe auf die ersten {output_limit} Variablen gekürzt)\")  \n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exportieren der NetCDF4-Dateien im CSV-Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Definieren eine Funktion zum Konvertieren von NetCDF-Daten in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Funktion zur Konvertierung von NetCDF-Daten in ein Pandas DataFrame\n",
    "def netcdf_to_dataframe(\n",
    "    nc_file,\n",
    "    bounding_box=None):\n",
    "\n",
    "    # Öffne das NetCDF-Dataset im Lesemodus\n",
    "    with xr.open_dataset(nc_file['path']) as nc_dataset:\n",
    "        # Zugriff auf die Variablendaten aus dem Datensatz\n",
    "        variable_data = nc_dataset[nc_file['variable_name']]\n",
    "\n",
    "        # Sicherstellen, dass die Namen für Breiten- und Längengrad korrekt sind\n",
    "        latitude_name = 'latitude' if 'latitude' in nc_dataset.coords else 'lat'\n",
    "        longitude_name = 'longitude' if 'longitude' in nc_dataset.coords else 'lon'\n",
    "        \n",
    "        # Falls eine Begrenzungsbox angegeben ist, die Daten filtern\n",
    "        if bounding_box:\n",
    "            filtered_data = variable_data.where(\n",
    "                (nc_dataset[latitude_name] >= bounding_box[1]) & (nc_dataset[latitude_name] <= bounding_box[3]) &\n",
    "                (nc_dataset[longitude_name] >= bounding_box[0]) & (nc_dataset[longitude_name] <= bounding_box[2]),\n",
    "                drop=True\n",
    "            )\n",
    "        else:\n",
    "            filtered_data = variable_data\n",
    "\n",
    "        # Umwandlung des xarray-Datensatzes in ein Pandas DataFrame\n",
    "        df = filtered_data.to_dataframe().reset_index().set_index(['time', latitude_name, longitude_name])\n",
    "\n",
    "        variable_column_name = f\"{nc_file['variable_name']}_{nc_file['rcp']}_{nc_file['rcp_statistic']}\"\n",
    "        df.rename(columns={nc_file['variable_name']: variable_column_name}, inplace=True)\n",
    "\n",
    "        # Entfernen nicht benötigter Spalten (variiert je nach Datensatz)\n",
    "        if 'height' in df.columns:\n",
    "            df = df.drop(columns=['height'])\n",
    "        if 'quantile' in df.columns:\n",
    "            df = df.drop(columns=['quantile'])\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 DataFrame erstellen und als zusammengeführte CSV-Datei exportieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import textwrap\n",
    "\n",
    "# Definieren Sie den Variablennamen für die Filterung von NetCDF-Dateien.\n",
    "variable_name = 'HWD_EU_climate'  # Andere Optionen: HWD_EU_climate, HWD_EU_health, HWD_merged (für HWD_national), oder CDS_national\n",
    "\n",
    "# Erstellen Sie einen Ordner für die Speicherung von CSV-Teilsatzdateien.\n",
    "subset_csv_folder = os.path.join(csv_folder, f\"{variable_name}\")\n",
    "os.makedirs(subset_csv_folder, exist_ok=True)  # Ensure the folder exists\n",
    "\n",
    "# Definieren Sie den Namen der CSV-Ausgabedatei anhand des Variablennamens und der ausgewählten Definition\n",
    "csv_filename = f\"{variable_name}_{selected_definition}.csv\"\n",
    "csv_filepath = os.path.join(subset_csv_folder, csv_filename)\n",
    "\n",
    "# Filtern Sie die Liste der NetCDF-Dateien so, dass nur diejenigen enthalten sind, die dem Variablennamen entsprechen\n",
    "nc_files_subset = list(filter(lambda nc_file: nc_file['variable_name'] == variable_name, nc_files))\n",
    "\n",
    "# Exportieren Sie die NetCDF-Dateien als zusammengeführte CSV-Datei\n",
    "if not os.path.isfile(csv_filepath):\n",
    "    dataframes = [netcdf_to_dataframe(nc_file) for nc_file in tqdm(nc_files_subset)]\n",
    "    df_merged = pd.concat(dataframes, axis=1)\n",
    "    df_merged.to_csv(csv_filepath, sep=',', encoding='utf8')\n",
    "else:\n",
    "    print(f\"Datei existiert bereits unter {csv_filepath}.\\nÜberspringen den Export.\")\n",
    "    print(\"Lesen bestehende CSV-Datei ein...\")\n",
    "    df_merged = pd.read_csv(csv_filepath).set_index(['time', 'lat', 'lon'])\n",
    "\n",
    "# Funktion zum Umbruch der Spaltennamen für bessere Lesbarkeit\n",
    "def wrap_column_names(df, width):\n",
    "    wrapped_columns = {col: \" \".join(textwrap.wrap(col, width)) for col in df.columns}\n",
    "    return df.rename(columns=wrapped_columns)\n",
    "    \n",
    "# Ändere die Pandas-Anzeigeoptionen\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "    \n",
    "# Zeige das DataFrame an\n",
    "df_wrapped = wrap_column_names(df_merged, width=14)\n",
    "df_wrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exportieren der NetCDF4-Datei nach GeoTIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Definieren eine Funktion zum Exportieren der NetCDF4-Datei als GeoTIFF-Datei(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rasterio.transform import from_origin\n",
    "import rasterio\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def main_export_geotiff(\n",
    "    nc_file,\n",
    "    bounding_box=None,\n",
    "    start_year=None,\n",
    "    end_year=None,\n",
    "    merged=None,\n",
    "    output_directory=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameter:\n",
    "        nc_file (dict): Ein Wörterbuch mit den Schlüsseln 'path' (Dateipfad), 'variable', 'rcp' und 'statistic'.\n",
    "        bounding_box (list): [lon_min, lat_min, lon_max, lat_max] (optional).\n",
    "        start_year (int): Startjahr für den Datensatz (optional).\n",
    "        end_year (int): Endjahr für den Datensatz (optional).\n",
    "        merged (bool): Ob ein zusammengeführtes GeoTIFF oder einzelne GeoTIFFs erstellt werden sollen (optional).\n",
    "        output_directory (str): Verzeichnis zum Speichern der Ausgabe-GeoTIFF-Dateien (optional).\n",
    "    \"\"\"\n",
    "     \n",
    "    # Öffnet die NetCDF-Datei\n",
    "    with nc.Dataset(nc_file['path'], 'r') as nc_dataset:\n",
    "        nc_dataset = nc.Dataset(nc_file['path'], 'r')\n",
    "        lon = nc_dataset['lon'][:]\n",
    "        lat = nc_dataset['lat'][:]\n",
    "                    \n",
    "        # Falls eine Begrenzungsbox angegeben wurde, filtere die Daten entsprechend\n",
    "        if bounding_box:\n",
    "            lon_min, lat_min, lon_max, lat_max = bounding_box\n",
    "            \n",
    "            indices_lat = np.where((lat >= lat_min) & (lat <= lat_max))[0]\n",
    "            indices_lon = np.where((lon >= lon_min) & (lon <= lon_max))[0]\n",
    "            start_lat, end_lat = indices_lat[0], indices_lat[-1] + 1\n",
    "            start_lon, end_lon = indices_lon[0], indices_lon[-1] + 1\n",
    "        else:\n",
    "            start_lat, end_lat = 0, len(lat)\n",
    "            start_lon, end_lon = 0, len(lon)\n",
    "        \n",
    "        lat = lat[start_lat:end_lat]\n",
    "        lon = lon[start_lon:end_lon]\n",
    "            \n",
    "        # Extrahiere die Zeitvariable und konvertiere sie in lesbare Datumsangaben\n",
    "        time_var = nc_dataset.variables['time']\n",
    "        time_units = time_var.units\n",
    "        time_calendar = getattr(time_var, \"calendar\", \"standard\")\n",
    "        cftime = nc.num2date(time_var[:], units=time_units, calendar=time_calendar)\n",
    "        \n",
    "        # Berechnet die räumliche Auflösung und die Rastertransformation\n",
    "        dx = abs(lon[1] - lon[0])\n",
    "        dy = abs(lat[1] - lat[0])\n",
    "        transform = from_origin(lon.min() - dx / 2, lat.min() - dy / 2, dx, -dy)\n",
    "            \n",
    "        # Bestimmt den verfügbaren Zeitraum\n",
    "        min_year = cftime[0].year\n",
    "        max_year = cftime[-1].year\n",
    "\n",
    "        if start_year and end_year:\n",
    "            # Passen Sie start_year und end_year basierend auf dem verfügbaren Zeitraum an\n",
    "            if start_year < min_year:\n",
    "                print(f\"Das angegebene Startjahr {start_year} liegt vor dem Datensatzbereich.\")\n",
    "                print(f\"Das Startjahr wird auf {min_year} angepasst.\")\n",
    "            if end_year > max_year:\n",
    "                print(f\"Das angegebene Endjahr {end_year} liegt nach dem Datensatzbereich.\")\n",
    "                print(f\"Das Endjahr wird auf {max_year} angepasst.\")\n",
    "\n",
    "            start_year = max(start_year, min_year)\n",
    "            end_year = min(end_year, max_year)\n",
    "        else:\n",
    "            # Standardmäßig wird der gesamte Datensatz verwendet\n",
    "            start_year = min_year\n",
    "            end_year = max_year\n",
    "            \n",
    "        # Findet die Indizes, die dem angegebenen Jahresbereich entsprechen\n",
    "        start_index = next(i for i, dt in enumerate(cftime) if dt.year == start_year)\n",
    "        end_index = next(i for i, dt in enumerate(cftime) if dt.year == end_year) + 1  # Full year (monthly data)\n",
    "        \n",
    "        # Extrahiere Variablen-Daten\n",
    "        variable_data = nc_dataset.variables[nc_file['variable_name']]\n",
    "        variable_data_subset = variable_data[start_index:end_index, start_lat:end_lat, start_lon:end_lon]\n",
    "        \n",
    "        if merged:\n",
    "            # Erstellt ein zusammengeführtes GeoTIFF mit allen Zeitscheiben als separate Bänder\n",
    "            if output_directory:\n",
    "                subset_directory_path = output_directory\n",
    "            else:\n",
    "                subset_directory_path = os.path.join(geotiff_folder, f\"{selected_variable}_{selected_definition}-merged\")\n",
    "                os.makedirs(subset_directory_path, exist_ok=True)\n",
    "\n",
    "            # Pfad der Ausgabedatei festlegen\n",
    "            output_filename = f\"{nc_file['variable_name']}_{nc_file['rcp']}_{nc_file['rcp_statistic']}_{start_year}-{end_year}.tif\"\n",
    "            output_filepath = os.path.join(subset_directory_path, output_filename)\n",
    "\n",
    "            # Erstellt eine GeoTIFF-Datei mit mehreren Bändern für jede Zeitscheibe\n",
    "            with rasterio.open(\n",
    "                output_filepath,\n",
    "                \"w\",\n",
    "                driver = \"GTiff\",\n",
    "                dtype = str(variable_data_subset.dtype),\n",
    "                width = variable_data_subset.shape[2],\n",
    "                height = variable_data_subset.shape[1],\n",
    "                count = variable_data_subset.shape[0],\n",
    "                crs = \"EPSG:4326\",\n",
    "                nodata = -9999,\n",
    "                transform=transform,        \n",
    "            ) as dst:\n",
    "                for year_index in tqdm(range(variable_data_subset.shape[0]),\n",
    "                                    desc=f\"Exportiere zusammengeführte GeoTIFF-Datei von {start_year} bis {end_year}\"):\n",
    "                    band_data = variable_data_subset[year_index,:,:]\n",
    "                    dt = cftime[start_index + year_index]\n",
    "                    band_desc = f\"{dt.year:04d}-{dt.month:02d}-{dt.day:02d}\"\n",
    "                    \n",
    "                    # Schreibe jede Jahresscheibe als Band\n",
    "                    dst.write(band_data, year_index + 1)\n",
    "                    dst.set_band_description(year_index + 1, band_desc)\n",
    "                    \n",
    "        else:\n",
    "            # Export als einzelne GeoTIFF-Dateien\n",
    "            if output_directory:\n",
    "                subset_directory_path = output_directory\n",
    "            else:\n",
    "                subset_directory_path = os.path.join(geotiff_folder, f\"{selected_variable}_{selected_definition}-individual\")\n",
    "                os.makedirs(subset_directory_path, exist_ok=True)\n",
    "            \n",
    "            for year_index in tqdm(range(variable_data_subset.shape[0]),\n",
    "                                   desc=\"Exportieren einzelner GeoTIFF-Dateien\"):\n",
    "                # Bestimmt das Datum für die aktuelle Zeitscheibe\n",
    "                dt = cftime[start_index + year_index]\n",
    "                dt_full = f\"{dt.year:04d}-{dt.month:02d}-{dt.day:02d}\"\n",
    "\n",
    "                # Definiert den Speicherort der Ausgabe-GeoTIFF-Datei            \n",
    "                output_filename = f\"{nc_file['variable_name']}_{nc_file['rcp']}_{nc_file['rcp_statistic']}_{dt_full}.tif\"\n",
    "                output_filepath = os.path.join(subset_directory_path, output_filename)\n",
    "\n",
    "                # Exportiert die aktuelle Zeitscheibe als GeoTIFF\n",
    "                with rasterio.open(\n",
    "                    output_filepath,\n",
    "                    \"w\",\n",
    "                    driver=\"GTiff\",\n",
    "                    dtype=str(variable_data_subset.dtype),\n",
    "                    width=variable_data_subset.shape[2],\n",
    "                    height=variable_data_subset.shape[1],\n",
    "                    count=1,\n",
    "                    crs=\"EPSG:4326\",\n",
    "                    nodata=-9999,\n",
    "                    transform=transform,\n",
    "                ) as dst:\n",
    "                    year_precipitation_data = variable_data_subset[year_index, :, :]\n",
    "                    dst.write(year_precipitation_data, 1)\n",
    "                    dst.set_band_description(1, f\"{dt.year:04d}-{dt.month:02d}-{dt.day:02d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Ausgewählte NetCDF4-Datei(en) in GeoTIFF-Datei(en) exportieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Exportieren Sie alle NetCDF-Dateien als zusammengeführte GeoTIFF-Dateien.\n",
    "    for nc_file in nc_files_subset:\n",
    "        main_export_geotiff(\n",
    "            nc_file=nc_file,\n",
    "            bounding_box=None,\n",
    "            merged=True\n",
    "            )\n",
    "\n",
    "    # Exportieren Sie alle NetCDF-Dateien als einzelne GeoTIFF-Dateien.\n",
    "    for nc_file in nc_files_subset:\n",
    "        main_export_geotiff(\n",
    "            nc_file=nc_file,\n",
    "            bounding_box=None,\n",
    "            start_year = 1995,\n",
    "            end_year = 2000,\n",
    "            merged = False,\n",
    "            )\n",
    "            \n",
    "    # Zusätzlicher Fall (Erweiterte Filterung)\n",
    "    # temp_folder = os.path.join(geotiff_folder, \"_temp_folder\")\n",
    "    # os.makedirs(temp_folder, exist_ok=True)\n",
    "    \n",
    "    # main_export_geotiff(\n",
    "    #     nc_file=nc_files[0],\n",
    "    #     bounding_box=bbox_wgs84_konstanz_standard,\n",
    "    #     start_year=1995,\n",
    "    #     end_year=2000,\n",
    "    #     merged=True,\n",
    "    #     output_directory=temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyse und Visualisierung Optionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Vorbereitung der Daten für die Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten für die Region Konstanz filtern (WGS84-Format)\n",
    "lon_min, lat_min, lon_max, lat_max = bbox_wgs84_konstanz_standard\n",
    "\n",
    "# DataFrame mit einer Abfrage filtern\n",
    "filtered_df = (\n",
    "    df_merged.query(\n",
    "        \"@lat_min <= lat <= @lat_max and @lon_min <= lon <= @lon_max\"\n",
    "    )\n",
    "    .reset_index()\n",
    "    .set_index(\"time\")\n",
    ")\n",
    "\n",
    "# DataFrame anzeigen\n",
    "df_wrapped = wrap_column_names(filtered_df, width=11)\n",
    "df_wrapped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Daten filtern und Monatsdurchschnitt berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gruppierung nach dem 'time'-Index und Berechnung des Durchschnitts für jede Gruppe\n",
    "filtered_df_average = filtered_df.groupby(level='time').mean()\n",
    "filtered_df_average = filtered_df_average.drop(columns=['lat', 'lon'])\n",
    "\n",
    "# DataFrame anzeigen\n",
    "df_wrapped = wrap_column_names(filtered_df_average, width=11)\n",
    "df_wrapped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Definieren einer Funktion zur Erstellung eines Liniendiagramms mit Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_with_shaded_area(ax, x, y_mean, y_stdev, line_color, fill_color, line_label, fill_label, marker_style):\n",
    "    \"\"\"Hilfsfunktion zum Plotten von Mittelwertlinien mit schattiertem Fehlerbereich.\"\"\"\n",
    "    ax.plot(x, y_mean, color=line_color, label=line_label, marker=marker_style, markevery=5, linestyle='--')\n",
    "    ax.fill_between(x, y_mean - y_stdev, y_mean + y_stdev, color=fill_color, alpha=0.3, label=fill_label)\n",
    "\n",
    "def plot_line_and_shade(filtered_df_average, variable_name_list):\n",
    "    # Diagramm erstellen\n",
    "    fig, ax = plt.subplots(figsize=(13, 7), facecolor='#f1f1f1', edgecolor='k')\n",
    "\n",
    "    y_max_list = []\n",
    "    y_min_list = []\n",
    "    for variable_name in variable_name_list:\n",
    "        # Daten für RCP4.5 plotten\n",
    "        plot_with_shaded_area(\n",
    "            ax=ax,\n",
    "            x=filtered_df_average.index,\n",
    "            y_mean=filtered_df_average[f\"{variable_name}_rcp45_mean\"],\n",
    "            y_stdev=filtered_df_average[f\"{variable_name}_rcp45_stdev\"],\n",
    "            line_color='#1f77b4',\n",
    "            fill_color='#aec7e8',\n",
    "            line_label=f\"{variable_name}_rcp45_mean\",\n",
    "            fill_label=f\"{variable_name}_rcp45_stdev\",\n",
    "            marker_style=None\n",
    "        )\n",
    "\n",
    "        # Daten für RCP8.5 plotten\n",
    "        plot_with_shaded_area(\n",
    "            ax=ax,\n",
    "            x=filtered_df_average.index,\n",
    "            y_mean=filtered_df_average[f\"{variable_name}_rcp85_mean\"],\n",
    "            y_stdev=filtered_df_average[f\"{variable_name}_rcp85_stdev\"],\n",
    "            line_color='#ff7f0e',\n",
    "            fill_color='#ffbb78',\n",
    "            line_label=f\"{variable_name}_rcp85_mean\",\n",
    "            fill_label=f\"{variable_name}_rcp85_stdev\",\n",
    "            marker_style=None\n",
    "        )\n",
    "        \n",
    "        # Dynamische Anpassung der Y-Achse\n",
    "        interval = 1\n",
    "        rcp45_min = filtered_df_average[f\"{variable_name}_rcp45_mean\"].min() - \\\n",
    "                    filtered_df_average[f\"{variable_name}_rcp45_stdev\"].max()\n",
    "        rcp85_min = filtered_df_average[f\"{variable_name}_rcp85_mean\"].min() - \\\n",
    "                    filtered_df_average[f\"{variable_name}_rcp85_stdev\"].max()\n",
    "        y_min = min(rcp45_min, rcp85_min) - 0.5\n",
    "        y_min = y_min // interval * interval\n",
    "\n",
    "        rcp45_max = filtered_df_average[f\"{variable_name}_rcp45_mean\"].max() + \\\n",
    "                    filtered_df_average[f\"{variable_name}_rcp45_stdev\"].max()\n",
    "        rcp85_max = filtered_df_average[f\"{variable_name}_rcp85_mean\"].max() + \\\n",
    "                    filtered_df_average[f\"{variable_name}_rcp85_stdev\"].max()\n",
    "        y_max = max(rcp45_max, rcp85_max) + 0.5\n",
    "        y_max = (y_max + interval) // interval * interval\n",
    "        \n",
    "        y_max_list.append(y_max)\n",
    "        y_min_list.append(y_min)\n",
    "\n",
    "    ax.set_ylim(min(y_min_list), max(y_max_list))\n",
    "    \n",
    "    # X-Achse für bessere Lesbarkeit anpassen\n",
    "    ax.set_xlim(filtered_df_average.index.min(), filtered_df_average.index.max())\n",
    "    ax.set_xticks(filtered_df_average.index[::5])\n",
    "    tick_positions = filtered_df_average.index[::5]\n",
    "    tick_labels = [str(pd.to_datetime(date).year) for date in tick_positions]\n",
    "    ax.set_xticks(ticks=tick_positions, labels=tick_labels, rotation=0)\n",
    "    \n",
    "    # Gitterlinien hinzufügen\n",
    "    ax.grid(visible=True, color='#b0b0b0', linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "    ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2f'))\n",
    "\n",
    "    # Achsenbeschriftungen und Titel anpassen\n",
    "    ax.set_xlabel('Jahr', fontsize=14)\n",
    "    ax.set_ylabel('Temperatur (°C)', fontsize=14, labelpad=10)\n",
    "    ax.set_title(\n",
    "        f\"{variable_name}\\n(Vergleich der Szenarien RCP 4.5 und RCP 8.5)\",\n",
    "        fontsize=14,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    \n",
    "    # Beschreibung und Quelle hinzufügen\n",
    "    plt.figtext(\n",
    "        0.65,\n",
    "        -0.075,\n",
    "        (\n",
    "            'Beschreibung: Gesamtzahl der Hitzewellentage und Kältetage.\\n'\n",
    "            'Temperaturstatistik für Europa, abgeleitet aus Klimaprojektionen.\\n'\n",
    "            'Copernicus Climate Change Service (C3S) Klimadatenspeicher (CDS).\\n'\n",
    "            'DOI: 10.24381/cds.8be2c014 (Zugriff am 14-10-2024)'\n",
    "        ),\n",
    "        ha='left',\n",
    "        va='center',\n",
    "        fontsize=9,\n",
    "        wrap=True,\n",
    "        backgroundcolor='w',\n",
    "    )\n",
    "    \n",
    "    # Legende Anpassungen\n",
    "    ax.legend(loc='upper left', fontsize=10, frameon=True, title='Scenario', title_fontsize=11)\n",
    "    \n",
    "    # Layout anpassen und Diagramm anzeigen\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Visualisierung des Liniendiagramms mit Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Variable des Einzeldatensatzes\n",
    "    # Dieser Code schlägt für Cold Spell Days fehl, weil die Daten für Konstanz leer sind\n",
    "    plot_line_and_shade(filtered_df_average=filtered_df_average,\n",
    "                        variable_name_list=[f\"{nc_files[0]['variable_name']}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Definieren eine Funktion zur Erstellung einer Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "\n",
    "def main_plt_plot(\n",
    "        nc_file=nc_file,\n",
    "        selected_year=None,\n",
    "        bounding_box=None):\n",
    "    \n",
    "    # Öffnet die NetCDF-Datei\n",
    "    nc_dataset = nc.Dataset(nc_file['path'], mode='r')\n",
    "    lat = nc_dataset.variables['lat'][:]\n",
    "    lon = nc_dataset.variables['lon'][:]\n",
    "\n",
    "    # Falls eine Begrenzungsbox angegeben wurde, filtere die Daten entsprechend\n",
    "    if bounding_box:\n",
    "        lat_indices = np.where((lat >= bounding_box[1]) & (lat <= bounding_box[3]))[0]\n",
    "        lon_indices = np.where((lon >= bounding_box[0]) & (lon <= bounding_box[2]))[0]\n",
    "\n",
    "        lat_subset = lat[lat_indices]\n",
    "        lon_subset = lon[lon_indices]\n",
    "    else:\n",
    "        lat_indices = slice(None)\n",
    "        lon_indices = slice(None)\n",
    "\n",
    "        lat_subset = lat\n",
    "        lon_subset = lon\n",
    "\n",
    "    # Extrahiere Variablen-Daten\n",
    "    variable_name = nc_file['variable_name']\n",
    "    variable_data = nc_dataset.variables[variable_name][..., lat_indices, lon_indices]\n",
    "    var_units = getattr(nc_dataset.variables[variable_name], \"units\", \"N/A\")\n",
    "\n",
    "    # Bestimmen Sie den Jahresindex auf der Grundlage von selected_year.\n",
    "    if selected_year < 1986:\n",
    "        year_index = 0\n",
    "        year = 1985\n",
    "    elif selected_year > 2085:\n",
    "        year_index = -1\n",
    "        year = 2085\n",
    "    else:\n",
    "        year_index = selected_year-1986\n",
    "        year = selected_year\n",
    "\n",
    "    # Extrahieren Sie die Daten für das ausgewählte Jahr.\n",
    "    band_data = variable_data[year_index]\n",
    "\n",
    "    # NaN-Werte für Perzentilberechnungen entfernen\n",
    "    band_data_nonan = band_data[~np.isnan(band_data)]\n",
    "    vmin = np.nanpercentile(band_data_nonan, 1)\n",
    "    vmax = np.nanpercentile(band_data_nonan, 99)\n",
    "\n",
    "    def dynamic_round(value):\n",
    "        # Bestimmen Sie die Größe des Wertes.\n",
    "        order_of_magnitude = np.floor(np.log10(abs(value)))\n",
    "        \n",
    "        # Verwenden Sie diese Größe, um die Genauigkeit dynamisch zu wählen.\n",
    "        if order_of_magnitude < -2:  # Werte kleiner als 0,01\n",
    "            return round(value, 3)\n",
    "        elif order_of_magnitude < -1:  # Werte zwischen 0,01 und 1\n",
    "            return round(value, 2)\n",
    "        elif order_of_magnitude < 0:  # Werte zwischen 1 und 10\n",
    "            return round(value, 1)\n",
    "        else:  # Werte 10 oder größer\n",
    "            return round(value)\n",
    "    \n",
    "    # Dynamische Rundung auf vmin und vmax anwenden\n",
    "    vmin = dynamic_round(vmin)\n",
    "    vmax = dynamic_round(vmax)\n",
    "\n",
    "    bins = 10\n",
    "    interval = (vmax - vmin) / bins\n",
    "    \n",
    "    # Erstellen Sie ein 2D-Netzgitter für die grafische Darstellung.\n",
    "    lon_grid, lat_grid = np.meshgrid(lon_subset, lat_subset)\n",
    "\n",
    "    # Erstelle die Figur\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(12, 8),\n",
    "        facecolor='#f1f1f1',\n",
    "        edgecolor='k',\n",
    "        subplot_kw={'projection': ccrs.PlateCarree()}\n",
    "    )\n",
    "\n",
    "    # Kartenmerkmale hinzufügen\n",
    "    ax.coastlines(edgecolor='black', linewidth=1.5)\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "    # Erstellen Sie ein Farbnetzdiagramm mit der angegebenen Farbkarte und den Grenzen.\n",
    "    cmap = plt.get_cmap(\"viridis\", bins)\n",
    "    pcm = ax.pcolormesh(\n",
    "        lon_grid,\n",
    "        lat_grid,\n",
    "        band_data,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        cmap=cmap,\n",
    "        shading='auto',\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        )\n",
    "    \n",
    "    # Einen Farbbalken hinzufügen\n",
    "    ticks = np.linspace(vmin, vmax, num=bins + 1)\n",
    "    cbar = plt.colorbar(pcm, ax=ax, orientation='vertical', pad=0.02, ticks=ticks)\n",
    "    cbar.set_label(f\"{variable_name}\", fontsize=12)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Gitterlinien hinzufügen\n",
    "    gl = ax.gridlines(draw_labels=True,\n",
    "                      crs=ccrs.PlateCarree(),\n",
    "                      linewidth=0.8,\n",
    "                      color='gray',\n",
    "                      alpha=0.7,\n",
    "                      linestyle='--')\n",
    "    gl.top_labels = False \n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {'size': 10, 'color': 'black'}\n",
    "    gl.ylabel_style = {'size': 10, 'color': 'black'}\n",
    "    \n",
    "    # Titel und Beschriftungen hinzufügen\n",
    "    fig.text(0.5, 0.0, 'Longitude', ha='center', fontsize=14)\n",
    "    fig.text(0.06, 0.5, 'Latitude', va='center', rotation='vertical', fontsize=14)\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    # Einen Titel hinzufügen\n",
    "    ax.set_title(f\"{variable_name}, {year}\", fontsize=14)\n",
    "\n",
    "    # Layout anpassen und das Diagramm anzeigen\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Visualisierung mit Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Beispiel für einen Anwendungsfall\n",
    "    main_plt_plot(nc_file=nc_files[0],\n",
    "                  selected_year=1990,\n",
    "                  )\n",
    "\n",
    "    main_plt_plot(nc_file=nc_files[0],\n",
    "                  selected_year=2010,\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
