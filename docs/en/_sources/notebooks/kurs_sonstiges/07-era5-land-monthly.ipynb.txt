{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5-Land Monthly Averaged\n",
    "\n",
    "ERA5-Land is a high-resolution reanalysis dataset that provides a consistent and detailed view of land variables over several decades, combining model data with atmospheric forcing from ERA5 to ensure accuracy. By correcting input variables for altitude differences and leveraging indirect observational influences, it offers enhanced precision for land surface applications like flood and drought forecasting. Despite some inherent uncertainties, ERA5-Land's extensive temporal and spatial resolution makes it a valuable resource for decision-making and environmental analysis.\n",
    "\n",
    "**Information on Dataset:**\n",
    "* Source: [ERA5-Land Monthly Data](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-monthly-means?tab=overview)\n",
    "* Author: str.ucture GmbH\n",
    "* Notebook-Version: 1.2 (Updated: March 05, 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Specifying the paths and working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' ---- Specify Directories Here ---- '''\n",
    "download_folder = r\".\\data\\era5-land-monthly-data\\download\"\n",
    "working_folder = r\".\\data\\era5-land-monthly-data\\working\"\n",
    "geotiff_folder = r\".\\data\\era5-land-monthly-data\\geotiff\"\n",
    "csv_folder = r\".\\data\\era5-land-monthly-data\\csv\"\n",
    "output_folder = r\".\\data\\era5-land-monthly-data\\output\"\n",
    "''' ----- End of Declaration ---- '''\n",
    "\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "os.makedirs(working_folder, exist_ok=True)\n",
    "os.makedirs(geotiff_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Extract the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "def main():\n",
    "    # API key for authentication\n",
    "    api_key = \"fdae60fd-35d4-436f-825c-c63fedab94a4\"\n",
    "    api_url = \"https://cds.climate.copernicus.eu/api\"\n",
    "\n",
    "    # Creation of the CDS API client\n",
    "    client = cdsapi.Client(url=api_url, key=api_key)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define the \"request\" and Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1fe86fc9ae4664814d37dc3fd460f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select a variable group', layout=Layout(width='50%'), options=('var_group_temperature', …"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import _utils.extra_era5_land_monthly as utils\n",
    "\n",
    "var_group_name_list = utils.var_group_name_list\n",
    "var_group_dict = utils.var_group_dict\n",
    "\n",
    "selected_variable_group = widgets.Dropdown(\n",
    "    options=var_group_name_list,\n",
    "    value=var_group_name_list[0],\n",
    "    description=\"Select a variable group\",\n",
    "    style=dict(description_width='initial'),\n",
    "    layout=widgets.Layout(width='50%'),\n",
    ")\n",
    "\n",
    "selected_variable_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8e48149562497b872631d390f63b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select the variable of interest', index=1, layout=Layout(width='50%'), options=('2m_dewp…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_variable_group = var_group_dict[selected_variable_group.value]\n",
    "\n",
    "selected_variable = widgets.Dropdown(\n",
    "    options=current_variable_group,\n",
    "    value=current_variable_group[1],\n",
    "    description=\"Select the variable of interest\",\n",
    "    style=dict(description_width='initial'),\n",
    "    layout=widgets.Layout(width='50%'),\n",
    ")\n",
    "\n",
    "selected_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define Bounding Box Extents (Bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounding box coordinates (WGS84 format)\n",
    "# The coordinates are in the format: [North, West, South, East]\n",
    "bbox_wgs84_deutschland = [56.0, 5.8, 47.2, 15.0]\n",
    "bbox_wgs84_de_standard = [5.7, 47.1, 15.2, 55.2]\n",
    "bbox_wgs84_konstanz = [47.9, 8.9, 47.6, 9.3]\n",
    "bbox_wgs84_konstanz_standard = [9.0, 47.6, 9.3, 47.8]  # Standard format: [West, South, East, North]\n",
    "\n",
    "# Alternatively, use a shapefile for precise geographic filtering\n",
    "import geopandas as gpd\n",
    "import math\n",
    "\n",
    "# Load the shapefile of Konstanz (WGS84 projection) for geographic boundary filtering\n",
    "de_shapefile = r\"./shapefiles/de_boundary.shp\"\n",
    "de_gdf = gpd.read_file(de_shapefile)\n",
    "\n",
    "# Extract the bounding box of the shapefile\n",
    "de_bounds = de_gdf.total_bounds\n",
    "\n",
    "# Adjust and buffer the bounding box to create a slightly larger\n",
    "de_bounds_adjusted = [(math.floor(de_bounds[0]* 10)/10)-0.1,\n",
    "                      (math.floor(de_bounds[1]* 10)/10)-0.1,\n",
    "                      (math.ceil(de_bounds[2]* 10)/10)+0.1,\n",
    "                      (math.ceil(de_bounds[3]* 10)/10)+0.1]\n",
    "\n",
    "# Rearrange the coordinates to the format: [North, West, South, East]\n",
    "bbox_de_bounds_adjusted = [de_bounds_adjusted[3], de_bounds_adjusted[0],\n",
    "                           de_bounds_adjusted[1], de_bounds_adjusted[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Define \"dataset\" and \"request\"\n",
    "\n",
    "Based on the selected **hour** of the day, the **product_type** varies in the request. For example:\n",
    "\n",
    "* For: product_type = monthly_averaged_reanalysis, the only available hour is 00:00.\n",
    "* For: product_type = monthly_averaged_reanalysis_by_hour_of_day, multiple hour (00:00 to 23:00) can be selected. Where, separate output bands are generated for average of each hour per month.\n",
    "\n",
    "This Notebook will primarily focus on the **monthly_averaged_reanalysis** product_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the dataset and the request parameters\n",
    "dataset = \"reanalysis-era5-land-monthly-means\"\n",
    "request = {\n",
    "    \"product_type\": [\"monthly_averaged_reanalysis\"],\n",
    "    \"variable\": selected_variable.value,\n",
    "    \"year\": [str(year) for year in range(1950,2025+1,1)],\n",
    "    \"month\": [str(month) for month in range(13)],\n",
    "    \"time\": [\"00:00\"], \n",
    "    \"data_format\": \"netcdf\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "    \"area\": bbox_de_bounds_adjusted\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded.\n"
     ]
    }
   ],
   "source": [
    "download_folder_subset = os.path.join(download_folder, f\"{request['product_type'][0]}\", f\"{selected_variable.value}\")\n",
    "os.makedirs(download_folder_subset, exist_ok=True)\n",
    "\n",
    "# Execute it to download the dataset:\n",
    "def main_retrieve():\n",
    "    dataset_filename = f\"{selected_variable.value}.nc\"\n",
    "    dataset_filepath = os.path.join(download_folder_subset, dataset_filename)\n",
    "\n",
    "    # Download the dataset only if the dataset has not been downloaded before\n",
    "    if not os.path.isfile(dataset_filepath):\n",
    "        # Call the CDS client only if the dataset has not been downloaded before\n",
    "        client = main()\n",
    "        # Download the dataset with the defined request parameters\n",
    "        client.retrieve(dataset, request, dataset_filepath)\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extract the ZIP file in folder\n",
    "\n",
    "> Note: Since the dataset is downloaded for a single variable, only 1 netCDF file is downloaded and CDS does not create a zip file for single variable netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "\n",
    "# extract_folder = os.path.join(working_folder, f\"{selected_variable.value}\")\n",
    "# os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "# # Extract the zip file\n",
    "# try:\n",
    "#     if not os.listdir(extract_folder):\n",
    "#         dataset_filename = dataset_filename = f\"{dataset}-{request['product_type'][0]}-{selected_variable.value}.nc\"\n",
    "#         dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "\n",
    "#         with zipfile.ZipFile(dataset_filepath, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(extract_folder)\n",
    "#             print(f\"Successfully extracted files to: {extract_folder}\")\n",
    "#     else:\n",
    "#         print(\"Folder is not empty. Skipping extraction.\")\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Error: The file {dataset_filepath} was not found.\")\n",
    "# except zipfile.BadZipFile:\n",
    "#     print(f\"Error: The file {dataset_filepath} is not a valid zip file.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Investigate the Metadata of the NetCDF4 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2m_temperature.nc']\n"
     ]
    }
   ],
   "source": [
    "# Print list of netCDF4 files inside the working/extracted folder\n",
    "filename_list = os.listdir(download_folder_subset)\n",
    "print(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available variables: ['number', 'valid_time', 'latitude', 'longitude', 'expver', 't2m']\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "# Define the file path for the selected NetCDF dataset\n",
    "nc_filename = '2m_temperature.nc'\n",
    "nc_filepath = os.path.join(download_folder_subset, nc_filename)\n",
    "\n",
    "# Open the NetCDF file in read mode\n",
    "nc_dataset = nc.Dataset(nc_filepath, mode='r')\n",
    "\n",
    "# List all variables in the dataset\n",
    "variables_list = list(nc_dataset.variables.keys())\n",
    "print(f\"Available variables: {list(variables_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Variable Name</td>\n",
       "      <td>t2m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shape</td>\n",
       "      <td>(902, 82, 96)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable Info</td>\n",
       "      <td>('valid_time', 'latitude', 'longitude')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Units</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Long Name</td>\n",
       "      <td>2 metre temperature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Description                                  Details\n",
       "0  Variable Name                                      t2m\n",
       "1      Data Type                                  float32\n",
       "2          Shape                            (902, 82, 96)\n",
       "3  Variable Info  ('valid_time', 'latitude', 'longitude')\n",
       "4          Units                                        K\n",
       "5      Long Name                      2 metre temperature"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define variable name from available variables and read variable data\n",
    "variable_name = 't2m'\n",
    "variable_data = nc_dataset[variable_name]\n",
    "\n",
    "# Create a summary of the primary variables\n",
    "summary = {\n",
    "    \"Variable Name\": variable_name,\n",
    "    \"Data Type\": variable_data.dtype,\n",
    "    \"Shape\": variable_data.shape,\n",
    "    \"Variable Info\": f\"{variable_data.dimensions}\",\n",
    "    \"Units\": getattr(variable_data, \"units\", \"N/A\"),\n",
    "    \"Long Name\": getattr(variable_data, \"long_name\", \"N/A\"),\n",
    "}\n",
    "\n",
    "# Display the summary of the data set as a DataFrame for better visualisation\n",
    "nc_summary = pd.DataFrame(list(summary.items()), columns=['Description', 'Details'])\n",
    "\n",
    "# Display the summary DataFrame\n",
    "nc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nc_variables</th>\n",
       "      <th>unit</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number</td>\n",
       "      <td>1</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid_time</td>\n",
       "      <td>seconds since 1970-01-01</td>\n",
       "      <td>(902,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>(82,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>degrees_east</td>\n",
       "      <td>(96,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expver</td>\n",
       "      <td>N/A</td>\n",
       "      <td>(902,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t2m</td>\n",
       "      <td>K</td>\n",
       "      <td>(902, 82, 96)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nc_variables                      unit          shape\n",
       "0       number                         1             ()\n",
       "1   valid_time  seconds since 1970-01-01         (902,)\n",
       "2     latitude             degrees_north          (82,)\n",
       "3    longitude              degrees_east          (96,)\n",
       "4       expver                       N/A         (902,)\n",
       "5          t2m                         K  (902, 82, 96)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a summary of all the variables of the dataset\n",
    "rows = []\n",
    "for variable in variables_list:\n",
    "    try:\n",
    "        var_obj = nc_dataset.variables[variable]\n",
    "        unit = getattr(var_obj, 'units', 'N/A')\n",
    "        shape = var_obj.shape\n",
    "        rows.append({\n",
    "            \"nc_variables\": variable,\n",
    "            \"unit\": unit,\n",
    "            \"shape\": shape\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing variable {variable}: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export the dataset in CSV Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Filter Data by Bounding Box and Export as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Function for converting NetCDF data into a Pandas DataFrame\n",
    "def netcdf_to_dataframe(nc_filepath, bounding_box=None):\n",
    "\n",
    "    with xr.open_dataset(nc_filepath) as nc_dataset:\n",
    "        # Access the variable data from the datase\n",
    "        variable_data = nc_dataset[variable_name]\n",
    "\n",
    "        # Ensure latitude and longitude names are correct\n",
    "        latitude_name = 'latitude' if 'latitude' in nc_dataset.coords else 'lat'\n",
    "        longitude_name = 'longitude' if 'longitude' in nc_dataset.coords else 'lon'\n",
    "\n",
    "        # Filter the data based on the bounding box, if provided\n",
    "        if bounding_box:\n",
    "            filtered_data = variable_data.where(\n",
    "                (nc_dataset['X'] >= bounding_box[0]) & (nc_dataset['X'] <= bounding_box[2]) &\n",
    "                (nc_dataset['Y'] >= bounding_box[1]) & (nc_dataset['Y'] <= bounding_box[3]),\n",
    "                drop=True\n",
    "            )\n",
    "        else:\n",
    "            filtered_data = variable_data\n",
    "\n",
    "        # Convert the xarray dataset to a pandas DataFrame\n",
    "        df = filtered_data.to_dataframe().reset_index()\n",
    "\n",
    "        # Remove columns that are not neeeded (varies depending on the data set)\n",
    "        if 'number' in df.columns:\n",
    "            df = df.drop(columns=['number'])\n",
    "        if 'expver' in df.columns:\n",
    "            df = df.drop(columns=['expver'])\n",
    "\n",
    "        # Separate valid_time into date and time\n",
    "        df['valid_time'] = pd.to_datetime(df['valid_time'])\n",
    "        df['date'] = df['valid_time'].dt.date\n",
    "        df['time'] = df['valid_time'].dt.time\n",
    "        df = df.set_index(['date', 'time', latitude_name, longitude_name])\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>valid_time</th>\n",
       "      <th>t2m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1950-01-01</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">00:00:00</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">55.2</th>\n",
       "      <th>5.7</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.8</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.9</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.1</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2025-02-01</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">00:00:00</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">47.1</th>\n",
       "      <th>14.8</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>271.331543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.9</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>271.675293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>272.151855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.1</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>272.720215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.2</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>273.452637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7100544 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       valid_time         t2m\n",
       "date       time     latitude longitude                       \n",
       "1950-01-01 00:00:00 55.2     5.7       1950-01-01         NaN\n",
       "                             5.8       1950-01-01         NaN\n",
       "                             5.9       1950-01-01         NaN\n",
       "                             6.0       1950-01-01         NaN\n",
       "                             6.1       1950-01-01         NaN\n",
       "...                                           ...         ...\n",
       "2025-02-01 00:00:00 47.1     14.8      2025-02-01  271.331543\n",
       "                             14.9      2025-02-01  271.675293\n",
       "                             15.0      2025-02-01  272.151855\n",
       "                             15.1      2025-02-01  272.720215\n",
       "                             15.2      2025-02-01  273.452637\n",
       "\n",
       "[7100544 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = netcdf_to_dataframe(nc_filepath=nc_filepath)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define csv filename and filepath for the output\n",
    "# csv_filename = f\"{nc_filename.replace('.nc','.csv')}\"\n",
    "# csv_folderpath = os.path.join(csv_folder, f\"{request['product_type'][0]}\")\n",
    "# os.makedirs(csv_folderpath, exist_ok=True)\n",
    "\n",
    "# csv_filepath = os.path.join(csv_folderpath, csv_filename)\n",
    "\n",
    "# csv_filepath# Export the DataFrame as CSV if it does not already exist\n",
    "# if not os.path.isfile(csv_filepath):\n",
    "#     dataframe = netcdf_to_dataframe(nc_filepath=nc_filepath)\n",
    "#     dataframe.to_csv(csv_filepath, sep=\",\", encoding='utf8')\n",
    "# else:\n",
    "#     print(f\"File already exists at {csv_filepath}.\\nSkipping export.\")\n",
    "#     print(\"Reading existing CSV file...\")\n",
    "#     dataframe = pd.read_csv(csv_filepath).set_index(['time', 'Y', 'X'])\n",
    "\n",
    "# # Display DataFrame\n",
    "# dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
