{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscaled bioclimatic indicators\n",
    "\n",
    "Available for Europe, Central Africa and Northern Brazil\n",
    "\n",
    "Alternative name: sis-biodiversity-era5-regional\n",
    "\n",
    "**Information on Dataset:**\n",
    "* Source: [Downscaled Bioclimatic Indicators](https://cds.climate.copernicus.eu/datasets/sis-biodiversity-era5-regional?tab=overview)\n",
    "* Author:\n",
    "* Resolution: 1 km x 1 km\n",
    "* Notebook Version: 1.1 (Updated: December 17. 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Specifying the paths and working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' ---- Hier die Verzeichnisse angeben ---- '''\n",
    "download_folder = r\".\\data\\sis-biodiversity-era5-regional\\download\"\n",
    "working_folder = r\".\\data\\sis-biodiversity-era5-regional\\working\"\n",
    "geotiff_folder = r\".\\data\\sis-biodiversity-era5-regional\\geotiff\"\n",
    "csv_folder = r\".\\data\\sis-biodiversity-era5-regional\\csv\"\n",
    "output_folder = r\".\\data\\sis-biodiversity-era5-regional\\output\"\n",
    "''' ----- Ende der Eingaben ---- '''\n",
    "\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "os.makedirs(working_folder, exist_ok=True)\n",
    "os.makedirs(geotiff_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Extract Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "def main():\n",
    "    api_key = \"fdae60fd-35d4-436f-825c-c63fedab94a4\"\n",
    "    api_url = \"https://cds.climate.copernicus.eu/api\"\n",
    "    client = cdsapi.Client(url=api_url, key=api_key)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Request Definition and Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define additional request fields to ensure the request stays within the file size limit.\n",
    "# These coordinates were obtained using the BBox Extractor tool:\n",
    "# https://str-ucture.github.io/bbox-extractor/\n",
    "\n",
    "bbox_wgs84_deutschland = [56.0, 5.8, 47.2, 15.0]\n",
    "bbox_wgs84_konstanz = [47.9, 8.9, 47.6, 9.3]\n",
    "\n",
    "# Alternatively, use a shapefile for precise geographic filtering\n",
    "import geopandas as gpd\n",
    "import math\n",
    "\n",
    "# Example: Load shapefile of Konstanz (WGS84 projection)\n",
    "de_shapefile = r\"./shapefiles/de_boundary.shp\"\n",
    "de_gdf = gpd.read_file(de_shapefile)\n",
    "de_bounds = de_gdf.total_bounds\n",
    "\n",
    "# Adjust and buffer\n",
    "de_bounds_adjusted = [(math.floor(de_bounds[0]* 10)/10)-0.1,\n",
    "                      (math.floor(de_bounds[1]* 10)/10)-0.1,\n",
    "                      (math.ceil(de_bounds[2]* 10)/10)+0.1,\n",
    "                      (math.ceil(de_bounds[3]* 10)/10)+0.1]\n",
    "\n",
    "bbox_de_bounds_adjusted = [de_bounds_adjusted[3], de_bounds_adjusted[0],\n",
    "                           de_bounds_adjusted[1], de_bounds_adjusted[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Currently for Region == Europe, only ERA5 is available\n",
    "# for Region == Central Africa, ERA5 is available\n",
    "# for Region == Northern Brazil, ERA5-Land is available\n",
    "\n",
    "## Variable group: Bioclimatic indicators as in WORLDCLIM\n",
    "# cds.climate.copernicus.eu/datasets/sis-biodiversity-era5-regional?tab=download\n",
    "variable_group = \"bioclimatic_indicators_as_in_worldclim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sis-biodiversity-era5-regional\"\n",
    "request = {\n",
    "    \"region\": [\"europe\"],\n",
    "    \"origin\": \"era5\",\n",
    "    \"variable\": [\n",
    "        \"annual_mean_temperature\",\n",
    "        \"mean_diurnal_range\",\n",
    "        \"isothermality\",\n",
    "        \"temperature_seasonality\",\n",
    "        \"maximum_temperature_of_warmest_month\",\n",
    "        \"minimum_temperature_of_coldest_month\",\n",
    "        \"temperature_annual_range\",\n",
    "        \"mean_temperature_of_wettest_quarter\",\n",
    "        \"mean_temperature_of_driest_quarter\",\n",
    "        \"mean_temperature_of_warmest_quarter\",\n",
    "        \"mean_temperature_of_coldest_quarter\",\n",
    "        \"annual_precipitation\",\n",
    "        \"precipitation_of_wettest_month\",\n",
    "        \"precipitation_of_driest_month\",\n",
    "        \"precipitation_seasonality\",\n",
    "        \"precipitation_of_wettest_quarter\",\n",
    "        \"precipitation_of_driest_quarter\",\n",
    "        \"precipitation_of_warmest_quarter\",\n",
    "        \"precipitation_of_coldest_quarter\"\n",
    "    ],\n",
    "    \"statistic\": [\n",
    "        \"mean\",\n",
    "        \"median\",\n",
    "        \"25th_quartile\",\n",
    "        \"75th_quartile\"\n",
    "    ],\n",
    "    \"version\": [\"1_0\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 09:21:34,791 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n",
      "2024-12-20 09:21:34,793 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2024-12-20 09:21:34,796 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n",
      "2024-12-20 09:21:34,799 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to download the dataset:\n",
    "def main_retrieve():\n",
    "    dataset_filename = f\"{dataset}_{variable_group}.zip\"\n",
    "    dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "\n",
    "    # Download the dataset only if the dataset has not been downloaded before\n",
    "    if not os.path.isfile(dataset_filepath):\n",
    "        # Download the dataset with the defined request parameters\n",
    "        client.retrieve(dataset, request, dataset_filepath)\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = main()\n",
    "    main_retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extract the Zip folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is not empty. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "extract_folder = os.path.join(working_folder, variable_group)\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "try:\n",
    "    if not os.listdir(extract_folder):\n",
    "        dataset_filename = f\"{dataset}_{variable_group}.zip\"\n",
    "        dataset_filepath = os.path.join(download_folder, dataset_filename)\n",
    "        \n",
    "        with zipfile.ZipFile(dataset_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_folder)\n",
    "            print(f\"Successfully extracted files to: {extract_folder}\")\n",
    "    else:\n",
    "        print(\"Folder is not empty. Skipping extraction.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {dataset_filepath} was not found.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(f\"Error: The file {dataset_filepath} is not a valid zip file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read the netCDF file and print the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ds_variable</th>\n",
       "      <th>ds_origin</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_shape</th>\n",
       "      <th>statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIO01_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO01</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO01</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIO01_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO01</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO01</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIO01_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO01</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO01</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>q25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIO01_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO01</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO01</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>q75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIO02_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO02</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO02</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>BIO18_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO18</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO18</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>q75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>BIO19_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO19</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO19</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>BIO19_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO19</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO19</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BIO19_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO19</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO19</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>q25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BIO19_era5-to-1km_1979-201...</td>\n",
       "      <td>BIO19</td>\n",
       "      <td>era5-to-1km_1979-2018</td>\n",
       "      <td>BIO19</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "      <td>q75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename ds_variable              ds_origin  \\\n",
       "0   BIO01_era5-to-1km_1979-201...       BIO01  era5-to-1km_1979-2018   \n",
       "1   BIO01_era5-to-1km_1979-201...       BIO01  era5-to-1km_1979-2018   \n",
       "2   BIO01_era5-to-1km_1979-201...       BIO01  era5-to-1km_1979-2018   \n",
       "3   BIO01_era5-to-1km_1979-201...       BIO01  era5-to-1km_1979-2018   \n",
       "4   BIO02_era5-to-1km_1979-201...       BIO02  era5-to-1km_1979-2018   \n",
       "..                            ...         ...                    ...   \n",
       "71  BIO18_era5-to-1km_1979-201...       BIO18  era5-to-1km_1979-2018   \n",
       "72  BIO19_era5-to-1km_1979-201...       BIO19  era5-to-1km_1979-2018   \n",
       "73  BIO19_era5-to-1km_1979-201...       BIO19  era5-to-1km_1979-2018   \n",
       "74  BIO19_era5-to-1km_1979-201...       BIO19  era5-to-1km_1979-2018   \n",
       "75  BIO19_era5-to-1km_1979-201...       BIO19  era5-to-1km_1979-2018   \n",
       "\n",
       "   variable_name   variable_shape statistic  \n",
       "0          BIO01  (1, 4800, 9600)      mean  \n",
       "1          BIO01  (1, 4800, 9600)    median  \n",
       "2          BIO01  (1, 4800, 9600)       q25  \n",
       "3          BIO01  (1, 4800, 9600)       q75  \n",
       "4          BIO02  (1, 4800, 9600)      mean  \n",
       "..           ...              ...       ...  \n",
       "71         BIO18  (1, 4800, 9600)       q75  \n",
       "72         BIO19  (1, 4800, 9600)      mean  \n",
       "73         BIO19  (1, 4800, 9600)    median  \n",
       "74         BIO19  (1, 4800, 9600)       q25  \n",
       "75         BIO19  (1, 4800, 9600)       q75  \n",
       "\n",
       "[76 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "def meta(filename):\n",
    "    match = re.search(r\"(?P<ds_variable>BIO\\d{2})_(?P<ds_origin>[\\w-]+)-(?P<statistic>mean|median|q25|q75)_v(?P<version>\\d+\\.\\d+)\", filename)\n",
    "    if not match:\n",
    "        raise ValueError(\"the given filename does not fit the expected naming scheme\")\n",
    "    \n",
    "    def get_nc_variable():\n",
    "        with nc.Dataset(os.path.join(extract_folder, filename), 'r') as nc_dataset:\n",
    "            nc_variable_name_list = nc_dataset.variables.keys()\n",
    "            # Primary variable\n",
    "            # In CDS dataset there is usually just 1 primary variable per dataset\n",
    "            # Modify index based on the index of primary variable in nc_variable_name_list\n",
    "            primary_variable_index = 3\n",
    "            primary_variable = [*nc_variable_name_list][primary_variable_index]\n",
    "            primary_variable_shape = np.shape(nc_dataset[primary_variable])\n",
    "            \n",
    "            return primary_variable, primary_variable_shape\n",
    "    \n",
    "    return dict(\n",
    "        filename=filename,\n",
    "        path=os.path.join(extract_folder, filename),\n",
    "        ds_variable=match.group('ds_variable'),\n",
    "        ds_origin=match.group('ds_origin'),\n",
    "        variable_name=get_nc_variable()[0],\n",
    "        variable_shape=get_nc_variable()[1],\n",
    "        statistic=match.group('statistic')\n",
    "    )\n",
    "\n",
    "# Beispielverzeichnis (angepasst an deine Umgebung)\n",
    "nc_files = [meta(f) for f in os.listdir(extract_folder) if f.endswith('.nc')]\n",
    "df_nc_files = pd.DataFrame.from_dict(nc_files)\n",
    "\n",
    "# Modify pandas display options\n",
    "pd.options.display.max_colwidth = 30\n",
    "\n",
    "# Display the DataFrame without displaying path\n",
    "df_nc_files.loc[:, df_nc_files.columns != 'path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Print the list and summary of uniqie variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  BIO01   : Available variables: ['latitude', 'longitude', 'time', 'BIO01']\n",
      "5  BIO02   : Available variables: ['latitude', 'longitude', 'time', 'BIO02']\n",
      "9  BIO03   : Available variables: ['latitude', 'longitude', 'time', 'BIO03']\n",
      "13 BIO04   : Available variables: ['latitude', 'longitude', 'time', 'BIO04']\n",
      "17 BIO05   : Available variables: ['latitude', 'longitude', 'time', 'BIO05']\n",
      "21 BIO06   : Available variables: ['latitude', 'longitude', 'time', 'BIO06']\n",
      "25 BIO07   : Available variables: ['latitude', 'longitude', 'time', 'BIO07']\n",
      "29 BIO08   : Available variables: ['latitude', 'longitude', 'time', 'BIO08']\n",
      "33 BIO09   : Available variables: ['latitude', 'longitude', 'time', 'BIO09']\n",
      "37 BIO10   : Available variables: ['latitude', 'longitude', 'time', 'BIO10']\n",
      "41 BIO11   : Available variables: ['latitude', 'longitude', 'time', 'BIO11']\n",
      "45 BIO12   : Available variables: ['latitude', 'longitude', 'time', 'BIO12']\n",
      "49 BIO13   : Available variables: ['latitude', 'longitude', 'time', 'BIO13']\n",
      "53 BIO14   : Available variables: ['latitude', 'longitude', 'time', 'BIO14']\n",
      "57 BIO15   : Available variables: ['latitude', 'longitude', 'time', 'BIO15']\n",
      "61 BIO16   : Available variables: ['latitude', 'longitude', 'time', 'BIO16']\n",
      "65 BIO17   : Available variables: ['latitude', 'longitude', 'time', 'BIO17']\n",
      "69 BIO18   : Available variables: ['latitude', 'longitude', 'time', 'BIO18']\n",
      "73 BIO19   : Available variables: ['latitude', 'longitude', 'time', 'BIO19']\n"
     ]
    }
   ],
   "source": [
    "seen_variables = set()\n",
    "for i, nc_file in enumerate(nc_files):\n",
    "    variable_name = nc_file['variable_name']\n",
    "    \n",
    "    if variable_name in seen_variables:\n",
    "        continue\n",
    "\n",
    "    # Open the NetCDF file in read mode\n",
    "    nc_dataset = nc.Dataset(nc_file['path'], mode='r')\n",
    "\n",
    "    # List all variables in the dataset\n",
    "    variables_list = nc_dataset.variables.keys()\n",
    "    print(f\"{i+1:<2} {variable_name:<8}: Available variables: {list(variables_list)}\")\n",
    "    \n",
    "    # Add the variable name to the seen set\n",
    "    seen_variables.add(variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nc_variables</th>\n",
       "      <th>unit</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latitude</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>(4800,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>longitude</td>\n",
       "      <td>degrees_east</td>\n",
       "      <td>(9600,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>time</td>\n",
       "      <td>days since 1999-01-01</td>\n",
       "      <td>(1,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIO01</td>\n",
       "      <td>K</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nc_variables                   unit            shape\n",
       "0     latitude          degrees_north          (4800,)\n",
       "1    longitude           degrees_east          (9600,)\n",
       "2         time  days since 1999-01-01             (1,)\n",
       "3        BIO01                      K  (1, 4800, 9600)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_file = nc_files[0]\n",
    "nc_dataset = nc.Dataset(nc_file['path'], mode='r')\n",
    "variables_list = list(nc_dataset.variables.keys())\n",
    "\n",
    "rows = []\n",
    "for test_var in variables_list:\n",
    "    try:\n",
    "        var_obj = nc_dataset.variables[test_var]\n",
    "        unit = getattr(var_obj, 'units', 'N/A')\n",
    "        shape = var_obj.shape\n",
    "        rows.append({\n",
    "            \"nc_variables\": test_var,\n",
    "            \"unit\": unit,\n",
    "            \"shape\": shape\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing variable {test_var}: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Print summary of primary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Variable Name</td>\n",
       "      <td>BIO01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shape</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable Info</td>\n",
       "      <td>('time', 'latitude', 'long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Units</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Long Name</td>\n",
       "      <td>Temperature annual mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Description                        Remarks\n",
       "0  Variable Name                          BIO01\n",
       "1      Data Type                        float32\n",
       "2          Shape                (1, 4800, 9600)\n",
       "3  Variable Info  ('time', 'latitude', 'long...\n",
       "4          Units                              K\n",
       "5      Long Name        Temperature annual mean"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Variable Name</td>\n",
       "      <td>BIO02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Type</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shape</td>\n",
       "      <td>(1, 4800, 9600)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable Info</td>\n",
       "      <td>('time', 'latitude', 'long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Units</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Long Name</td>\n",
       "      <td>Mean diurnal range (mean o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Description                        Remarks\n",
       "0  Variable Name                          BIO02\n",
       "1      Data Type                        float32\n",
       "2          Shape                (1, 4800, 9600)\n",
       "3  Variable Info  ('time', 'latitude', 'long...\n",
       "4          Units                              K\n",
       "5      Long Name  Mean diurnal range (mean o..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n"
     ]
    }
   ],
   "source": [
    "seen_variables = set()\n",
    "for i, nc_file in enumerate(nc_files):\n",
    "    variable_name = nc_file['variable_name']\n",
    "    \n",
    "    if variable_name in seen_variables:\n",
    "        continue\n",
    "    \n",
    "    nc_dataset = nc.Dataset(nc_file['path'], mode='r')\n",
    "    variable_data = nc_dataset[variable_name]\n",
    "    \n",
    "    # Generate summary of the primary variable\n",
    "    summary = {\n",
    "        \"Variable Name\": variable_name,\n",
    "        \"Data Type\": variable_data.dtype,\n",
    "        \"Shape\": variable_data.shape,\n",
    "        \"Variable Info\": f\"{variable_data.dimensions}\",\n",
    "        \"Units\": getattr(variable_data, \"units\", \"N/A\"),\n",
    "        \"Long Name\": getattr(variable_data, \"long_name\", \"N/A\"),\n",
    "    }\n",
    "    \n",
    "    # Display dataset summary as a DataFrame for better visualization\n",
    "    nc_summary = pd.DataFrame(list(summary.items()), columns=['Description', 'Remarks'])\n",
    "\n",
    "    # Display the summary DataFrame\n",
    "    print(f\"{i+1}.\")\n",
    "    display(nc_summary)\n",
    "    \n",
    "    # Add the variable name to the seen set\n",
    "    seen_variables.add(variable_name)\n",
    "    if len(seen_variables)>=2:\n",
    "        print(\"....\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export Dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xarray as xr\n",
    "# nc_filepath = os.path.join(extract_folder, 'BIO01_era5-to-1km_1979-2018-mean_v1.0.nc')\n",
    "# variable_name = 'BIO01'\n",
    "\n",
    "# # Open the NetCDF dataset using xarray\n",
    "# with xr.open_dataset(nc_filepath) as nc_dataset:\n",
    "#     variable_data = nc_dataset[variable_name]\n",
    "\n",
    "#     # Apply geographic filtering using the defined bounding box\n",
    "#     filtered_data = variable_data.where(\n",
    "#         (nc_dataset['longitude'] >= bbox_de_bounds_standard[0]) & (nc_dataset['longitude'] <= bbox_de_bounds_standard[2]) &\n",
    "#         (nc_dataset['latitude'] >= bbox_de_bounds_standard[1]) & (nc_dataset['latitude'] <= bbox_de_bounds_standard[3]),\n",
    "#         drop=True\n",
    "#     )\n",
    "#     # Convert the filtered data into a DataFrame\n",
    "#     filtered_df = filtered_data.to_dataframe().reset_index()\n",
    "\n",
    "# # Modify display format for numbers in the DataFrames\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# # Display the filtered DataFrame\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netcdf_to_dataframe(nc_file, bounding_box=None):\n",
    "    \"\"\"\n",
    "    Converts a netCDF file to a DataFrame, optionally filtering by a bounding box.\n",
    "    \n",
    "    Parameters:\n",
    "        nc_file (dict): Dictionary with keys.\n",
    "        bounding_box (list): Bounding box as [lon_min, lat_min, lon_max, lat_max] (optional).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with time, latitude, longitude, and the variable's values.\n",
    "    \"\"\"\n",
    "    # Open the netCDF file\n",
    "    with nc.Dataset(nc_file['path'], 'r') as nc_dataset:\n",
    "        lon = nc_dataset['longitude'][:]\n",
    "        lat = nc_dataset['latitude'][:]\n",
    "        \n",
    "        # Extract time and convert it to readable dates\n",
    "        time_var = nc_dataset.variables['time']\n",
    "        time_units = time_var.units\n",
    "        time_calendar = getattr(time_var, \"calendar\", \"standard\")\n",
    "        cftime = nc.num2date(time_var[:], units=time_units, calendar=time_calendar)\n",
    "        \n",
    "        # Filter by bounding box if provided\n",
    "        if bounding_box:\n",
    "            lon_min, lat_min, lon_max, lat_max = bounding_box\n",
    "            lat_mask = (lat >= lat_min) & (lat <= lat_max)\n",
    "            lon_mask = (lon >= lon_min) & (lon <= lon_max)\n",
    "\n",
    "            lat_indices = np.where(lat_mask)[0]\n",
    "            lon_indices = np.where(lon_mask)[0]\n",
    "        else:\n",
    "            lat_indices = slice(None)\n",
    "            lon_indices = slice(None)\n",
    "\n",
    "        filtered_lat = lat[lat_indices]\n",
    "        filtered_lon = lon[lon_indices]\n",
    "        \n",
    "        # Extract variable data, slicing as needed\n",
    "        variable_data_subset = nc_dataset.variables[nc_file['variable_name']][..., lat_indices, lon_indices]\n",
    "        \n",
    "    # Flatten the data using NumPy\n",
    "    \"\"\"Modify the variable_column_name to reuse the function\"\"\"\n",
    "    \n",
    "    if 'variable_name' in nc_file and 'rcp' in nc_file and 'rcp_statistic' in nc_file:\n",
    "        variable_column_name = f\"{nc_file['variable_name']}_{nc_file['rcp']}_{nc_file['rcp_statistic']}\"\n",
    "    elif 'variable_name' in nc_file and 'statistic' in nc_file:\n",
    "        variable_column_name = f\"{nc_file['variable_name']}_{nc_file['statistic']}\"\n",
    "    elif 'variable_name' in nc_file:\n",
    "        variable_column_name = f\"{nc_file['variable_name']}\"\n",
    "    else:\n",
    "        variable_column_name = None\n",
    "        print(\"The required keys are missing in the 'nc_file' dictionary.\")\n",
    "\n",
    "    # Create rows for the DataFrame\n",
    "    rows = []\n",
    "    for t in range(variable_data_subset.shape[0]):\n",
    "        for i in range(variable_data_subset.shape[1]):\n",
    "            for j in range(variable_data_subset.shape[2]):\n",
    "                if not np.ma.is_masked(variable_data_subset[t, i, j]):\n",
    "                    rows.append({\n",
    "                        'time': cftime[t],\n",
    "                        'latitude': filtered_lat[i],\n",
    "                        'longitude': filtered_lon[j],\n",
    "                        variable_column_name: variable_data_subset[t, i, j]\n",
    "                    })\n",
    "                \n",
    "    # Create a DataFrame from the rows\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['time'] = pd.to_datetime(df['time'].map(str))\n",
    "    df['latitude'] = pd.to_numeric(df['latitude'])\n",
    "    df['longitude'] = pd.to_numeric(df['longitude'])\n",
    "    df[variable_column_name] = pd.to_numeric(df[variable_column_name])\n",
    "    \n",
    "    # Set the index to time, latitude, and longitude\n",
    "    return df.set_index(['time', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>BIO01_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">1999-01-01</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">32.004167</th>\n",
       "      <th>-29.995833</th>\n",
       "      <td>293.614014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-29.987500</th>\n",
       "      <td>293.613007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-29.979167</th>\n",
       "      <td>293.612030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-29.970833</th>\n",
       "      <td>293.611053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-29.962500</th>\n",
       "      <td>293.610077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">71.995833</th>\n",
       "      <th>49.962500</th>\n",
       "      <td>271.485382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.970833</th>\n",
       "      <td>271.481079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.979167</th>\n",
       "      <td>271.476807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.987500</th>\n",
       "      <td>271.472534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.995833</th>\n",
       "      <td>271.468231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46080000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 BIO01_mean\n",
       "time       latitude  longitude             \n",
       "1999-01-01 32.004167 -29.995833  293.614014\n",
       "                     -29.987500  293.613007\n",
       "                     -29.979167  293.612030\n",
       "                     -29.970833  293.611053\n",
       "                     -29.962500  293.610077\n",
       "...                                     ...\n",
       "           71.995833  49.962500  271.485382\n",
       "                      49.970833  271.481079\n",
       "                      49.979167  271.476807\n",
       "                      49.987500  271.472534\n",
       "                      49.995833  271.468231\n",
       "\n",
       "[46080000 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nc_file = nc_files[0]\n",
    "# netcdf_to_dataframe(nc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create DataFrame and Export as merged CSV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
