{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c77b62",
   "metadata": {},
   "source": [
    "# 2D Air Temperature Aggregation Tool\n",
    "\n",
    "This notebook provides a robust tool for extracting 2-meter air temperature (`ta_2m`) data from PALM (Potsdam Atmospheric Large-Eddy Simulation Model) 2D NetCDF output files and performing temporal aggregation. The primary goal is to generate aggregated `ta_2m` NetCDF files (e.g., hourly averages) from potentially finer-resolution simulation outputs. These aggregated files can then be used as input for subsequent analysis notebooks, streamlining data workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bea664",
   "metadata": {},
   "source": [
    "## 1. Import dependencies\n",
    "\n",
    "This section imports all necessary Python libraries for numerical operations, NetCDF file handling, interactive widget creation for user input, and basic operating system interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a43965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import os\n",
    "from utils import palm_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38453ba",
   "metadata": {},
   "source": [
    "## 2. Load Simulation Data\n",
    "This section defines the file paths for the 2D simulation output NetCDF files (for a baseline and a scenario run) and the static driver file. These files are then loaded into netCDF4 Dataset objects, making their contents accessible for processing. The static driver is included for potential future use (e.g., extracting building masks or grid information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e7b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute URLs (paths) of 2D xy-averaged simulation output files.\n",
    "file_xy_1 = r\"./Data/_simulation_outputs_3/konstanz_4096x4096_v9_Baseline-48hr/OUTPUT/konstanz_4096x4096_v9_Baseline_av_xy_N03.000.nc\"\n",
    "file_xy_2 = r\"./Data/_simulation_outputs_3/konstanz_4096x4096_v9_Scenario_1-48hr/OUTPUT/konstanz_4096x4096_v9_Scenario_1_av_xy_N03.000.nc\"\n",
    "file_static = r\"./Data/_simulation_outputs_3/konstanz_4096x4096_v9_Scenario_1-48hr/INPUT/konstanz_4096x4096_v9_Scenario_1_static_N03\"\n",
    "\n",
    "# Read NetCDF files into Dataset objects in read mode ('r').\n",
    "dataset_1 = nc.Dataset(file_xy_1, mode='r')\n",
    "dataset_2 = nc.Dataset(file_xy_2, mode='r')\n",
    "dataset_3 = nc.Dataset(file_static, mode='r') # Loaded for completeness, but not explicitly used later in *this* notebook.\n",
    "\n",
    "# Store the Dataset objects and their corresponding file paths in lists for easy iteration.\n",
    "file_xy_list = [file_xy_1, file_xy_2]\n",
    "dataset_list = [dataset_1, dataset_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49319a4c",
   "metadata": {},
   "source": [
    "## 3. Variable Selection\n",
    "This section allows the user to interactively select a 2D variable from the loaded NetCDF datasets. A dropdown widget is provided for selection, and the chosen variable's description and unit (retrieved from the palm_variables module) are displayed for clear identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88b3519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9348519b44dc4e1fa68d2a5942065ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select test variable:', options=('ta_2m*_xy', 'tsurf*_xy', 'wspeed_10m*_xy', 'bio_pet*_x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract variable names from the first dataset where the number of dimensions is greater than 2.\n",
    "# In PALM xy-averaged output files (`_av_xy_N03.000.nc`), these typically represent 2D spatial data over time (time, z_fixed_level, y, x) or (time, y, x).\n",
    "var_names_palm = [var for var in dataset_1.variables if dataset_1.variables[var].ndim > 2]\n",
    "\n",
    "# Initialize `test_variable` with the first variable in the list (`var_names_palm[0]`),\n",
    "# which is commonly 'ta_2m*_xy' for 2-m air temperature in these types of files.\n",
    "test_variable = var_names_palm[0]\n",
    "\n",
    "# Create a dropdown widget to allow the user to select the desired 2D variable.\n",
    "drop_down = widgets.Dropdown(\n",
    "    options=var_names_palm,         # Populate the dropdown with the extracted 2D variable names.\n",
    "    value=var_names_palm[0],        # Set the initial selected value in the dropdown.\n",
    "    description='Select test variable:' # Label displayed next to the dropdown.\n",
    ")\n",
    "\n",
    "# Define a handler function that will be called whenever the dropdown's value changes.\n",
    "def dropdown_handler(change):\n",
    "    global test_variable  # Declare `test_variable` as global to modify it.\n",
    "    test_variable = change.new     # Update the global `test_variable` with the newly selected value.\n",
    "    print(f\"Selected variable: {test_variable}\") # Print the newly selected variable to the console.\n",
    "\n",
    "# Attach the `dropdown_handler` function to observe changes in the 'value' property of the dropdown.\n",
    "drop_down.observe(dropdown_handler, names='value')\n",
    "\n",
    "# Display the dropdown widget in the notebook output.\n",
    "display(drop_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a259a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-m air temperature, °C\n"
     ]
    }
   ],
   "source": [
    "# Check if the selected `test_variable` string contains a wildcard character '*'.\n",
    "# This is common for PALM 2D xy-averaged variables (e.g., 'ta_2m*_xy').\n",
    "if \"*\" in test_variable:\n",
    "    # If a wildcard is present, extract the base part of the variable name (e.g., 'ta_2m' from 'ta_2m*_xy')\n",
    "    # and re-append '*' to match the keys in `palm_variables.variables_dict`.\n",
    "    var_initial = test_variable.split(\"*\")[0] + \"*\"\n",
    "    # Retrieve the dictionary of information for `var_initial` from the `palm_variables` module.\n",
    "    variable_info = palm_variables.variables_dict.get(var_initial, {})\n",
    "    # Extract the 'unit' from `variable_info`, defaulting to 'No unit available' if the key is missing.\n",
    "    unit = variable_info.get('unit', 'No unit available')\n",
    "    # Extract the 'description' from `variable_info`, defaulting to 'No description available' if the key is missing.\n",
    "    description = variable_info.get('description', 'No description available')\n",
    "    # Print the capitalized description and its unit.\n",
    "    print(f\"{description.capitalize()}, {unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1051d",
   "metadata": {},
   "source": [
    "## 4. Define Time Sequences and Aggregation Logic\n",
    "This section dynamically extracts the total number of time steps from the loaded dataset. It then defines the get_aggregate_time_list function, which creates lists of time step indices for temporal aggregation. This function generates moving windows of time steps, enabling the calculation of aggregated values (e.g., averages) over specified durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad11109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_time_list(total_time_steps, aggregate_time_steps):\n",
    "    \"\"\"\n",
    "    Generates a list of time step ranges for temporal aggregation, creating a moving window.\n",
    "\n",
    "    Args:\n",
    "        total_time_steps (int): Total number of time steps in the simulation.\n",
    "        aggregate_time_steps (int): The size of the aggregation window (number of time steps).\n",
    "\n",
    "    Returns:\n",
    "        list: A list where each element is a sub-list of time step indices\n",
    "              representing an aggregation window.\n",
    "    \"\"\"\n",
    "    time_lists = []\n",
    "    \n",
    "    for i in range(total_time_steps):\n",
    "        if aggregate_time_steps <= 1:\n",
    "            time_list = [i] # No aggregation: window is just the current time step.\n",
    "        else:\n",
    "            half_window = aggregate_time_steps // 2 # Calculate half-window size.\n",
    "            \n",
    "            # Determine the start and end indices of the window based on even/odd `aggregate_time_steps`.\n",
    "            if aggregate_time_steps % 2 == 0:\n",
    "                # For even window, it's centered such that `i` is towards the end of the first half.\n",
    "                # Example: for aggregate_time_steps=6, half_window=3. For `i=10`, range is [7, 13) -> [7, 8, 9, 10, 11, 12].\n",
    "                time_list = [j for j in range(i - half_window, i + half_window)]\n",
    "            else:\n",
    "                # For odd window, it's perfectly centered around `i`.\n",
    "                # Example: for aggregate_time_steps=5, half_window=2. For `i=10`, range is [8, 13) -> [8, 9, 10, 11, 12].\n",
    "                time_list = [j for j in range(i - half_window, i + half_window + 1)]\n",
    "        \n",
    "        # Filter out time indices that are outside the total simulation time steps.\n",
    "        valid_time_list = [j for j in time_list if 0 <= j < total_time_steps]\n",
    "        time_lists.append(valid_time_list)\n",
    "    \n",
    "    return time_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21bc26d",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Aggregation\n",
    "This section prepares the necessary data for the aggregation process. It extracts the base filenames from the input simulation files and loads the selected 2D variable data from both dataset_1 and dataset_2. It also sets the aggregate_time_steps parameter (defaulting to 1, meaning no aggregation is performed by default) and generates the corresponding time_lists for aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fedb2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the base filename (without path and extension) from the first xy output file.\n",
    "# This will be used in naming the aggregated output files.\n",
    "filename_xy_1 = os.path.basename(file_xy_1).split('.')[0]\n",
    "# Extract the base filename for the second xy output file.\n",
    "# Corrected from original: ensure `filename_xy_2` comes from `file_xy_2`.\n",
    "filename_xy_2 = os.path.basename(file_xy_2).split('.')[0]\n",
    "\n",
    "# Load the actual variable data for the selected `test_variable` from both `dataset_1` and `dataset_2`.\n",
    "# `test_variable` is determined by the dropdown selection in a previous step.\n",
    "variable_data_1 = dataset_1[test_variable]\n",
    "variable_data_2 = dataset_2[test_variable]\n",
    "\n",
    "# Get the full shape of the 2D variable data (time, y, x) from `dataset_1`.\n",
    "# The first element (`[0]`) gives the total number of time steps.\n",
    "variable_data_shape = np.shape(dataset_1[test_variable])\n",
    "total_time_steps = variable_data_shape[0]\n",
    "\n",
    "# Define the aggregation window size.\n",
    "# A value of 1 means no aggregation (individual time steps are processed).\n",
    "# Change this value (e.g., to 6 for hourly averages) to perform temporal aggregation.\n",
    "aggregate_time_steps = 1 # Default to no aggregation.\n",
    "\n",
    "# Generate the list of time step ranges for aggregation based on the defined window.\n",
    "# This list (`time_lists`) will guide the averaging process.\n",
    "time_lists = get_aggregate_time_list(total_time_steps, aggregate_time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc7c8b",
   "metadata": {},
   "source": [
    "## 6. Perform Aggregation and Save Data\n",
    "This final section iterates through the loaded simulation datasets. For each dataset, it computes the temporal aggregate of the selected 2D variable using the previously defined aggregation windows (time_lists). The aggregated data is then saved into new NetCDF files, organized in a subdirectory named after the aggregation window size. A check is included to skip the export if the file already exists to prevent accidental overwrites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f032391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping export: File already exists at ./output/04_aggregated_2D_data/konstanz_4096x4096_v9_Baseline_av_xy_N03_ta_2m_xy.nc\n",
      "Skipping export: File already exists at ./output/04_aggregated_2D_data/konstanz_4096x4096_v9_Scenario_1_av_xy_N03_ta_2m_xy.nc\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each dataset in the `dataset_list` (e.g., Baseline and Scenario 1 simulations).\n",
    "for i, current_dataset in enumerate(dataset_list):\n",
    "    # Extract the variable data for the `test_variable` from the current dataset.\n",
    "    variable_data = current_dataset[test_variable]\n",
    "    \n",
    "    # Get the total number of time steps for the current variable data.\n",
    "    current_total_time_steps = np.shape(variable_data)[0]\n",
    "    \n",
    "    # Regenerate `time_lists` to ensure it's correct for the current dataset's total time steps,\n",
    "    # in case datasets have different lengths or `aggregate_time_steps` was changed.\n",
    "    time_lists = get_aggregate_time_list(current_total_time_steps, aggregate_time_steps)\n",
    "    \n",
    "    # Initialize a list to store the aggregated 2D arrays for all time steps.\n",
    "    variable_data_agg = []\n",
    "    \n",
    "    # Loop through each generated time window (`time_list`) to compute the aggregate.\n",
    "    for j, time_window_indices in enumerate(time_lists):\n",
    "        values_in_window = []\n",
    "        \n",
    "        # For each time index within the current window, extract the 2D slice of the variable.\n",
    "        # Assuming `variable_data` has dimensions (time, z_fixed_level, y, x) or (time, y, x).\n",
    "        # If it's 4D (time, z, y, x), `variable_data[time_idx, 0, :, :]` extracts the 2D slice at z=0.\n",
    "        # If it's 3D (time, y, x), `variable_data[time_idx, :, :]` extracts the 2D slice directly.\n",
    "        # The following handles both cases assuming `z_fixed_level` is at index 1 if present.\n",
    "        if variable_data.ndim == 4:\n",
    "            for time_idx in time_window_indices:\n",
    "                values_in_window.append(variable_data[time_idx, 0, :, :])\n",
    "        elif variable_data.ndim == 3:\n",
    "            for time_idx in time_window_indices:\n",
    "                values_in_window.append(variable_data[time_idx, :, :])\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected number of dimensions for variable {test_variable}: {variable_data.ndim}\")\n",
    "            \n",
    "        # Compute the mean of all 2D slices collected in the current window along the time axis (axis=0).\n",
    "        # This results in a single 2D array representing the aggregated value for that time window.\n",
    "        variable_data_agg.append(np.mean(values_in_window, axis=0))\n",
    "        \n",
    "    # Determine the base filename for the output NetCDF file from the original file path.\n",
    "    source_filename = os.path.basename(file_xy_list[i]).split('.')[0]\n",
    "    \n",
    "    # Construct the `output_filename` by appending the `test_variable` name (with '*' removed if present).\n",
    "    output_filename = f\"{source_filename}_{test_variable.replace('*','')}\"\n",
    "    \n",
    "    # Define the output directory path.\n",
    "    output_directory = f\"./output/04_aggregated_2D_data/\" # Example: ./output/aggregated_2D_data/\n",
    "    # Create the output directory if it doesn't already exist. `exist_ok=True` prevents an error if it exists.\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Construct the full output file path.\n",
    "    output_filepath = os.path.join(output_directory, f\"{output_filename}.nc\")\n",
    "\n",
    "    # --- Check if file already exists; if so, skip export ---\n",
    "    if os.path.exists(output_filepath):\n",
    "        print(f\"Skipping export: File already exists at {output_filepath}\")\n",
    "        continue # Skip to the next iteration of the loop for the next dataset\n",
    "    \n",
    "    # Create a new NetCDF file in write mode (\"w\").\n",
    "    # `nc.Dataset` is used for creating and writing to NetCDF files.\n",
    "    with nc.Dataset(output_filepath, mode=\"w\", format='NETCDF4_CLASSIC') as output_dataset:\n",
    "        # --- Copy Global Attributes ---\n",
    "        # Iterate through all global attributes of the input dataset.\n",
    "        for attr_name in current_dataset.ncattrs():\n",
    "            # Exclude \"VAR_LIST\" from direct copying as it will be reconstructed.\n",
    "            if attr_name != \"VAR_LIST\":\n",
    "                output_dataset.setncattr(attr_name, current_dataset.getncattr(attr_name))\n",
    "        \n",
    "        # Reconstruct and set the \"VAR_LIST\" attribute for the output file.\n",
    "        # This attribute lists the variables contained within the new file, formatted as ';var1;var2;'.\n",
    "        var_list_str = \"\".join([f\";{var}\" for var in [test_variable]]) + \";\" # Only `test_variable` is exported.\n",
    "        output_dataset.setncattr('VAR_LIST', var_list_str)\n",
    "        \n",
    "        # --- Create Dimensions ---\n",
    "        # Get dimensions from the *first* variable (or general structure) of the input dataset.\n",
    "        # Assuming `variable_data` is (time, (z_level), y, x)\n",
    "        \n",
    "        # `num_time`: number of aggregated time steps.\n",
    "        # `num_z_level`: fixed to 1 as we're exporting a single 2D layer (e.g., z=0).\n",
    "        # `num_y`: number of rows in the 2D array.\n",
    "        # `num_x`: number of columns in the 2D array.\n",
    "        num_time = len(variable_data_agg)\n",
    "        num_z_level = 1 \n",
    "        num_y = variable_data_agg[0].shape[0] # Number of rows (y-dimension)\n",
    "        num_x = variable_data_agg[0].shape[1] # Number of columns (x-dimension)\n",
    "        \n",
    "        output_dataset.createDimension('time', num_time)\n",
    "        output_dataset.createDimension('z', num_z_level) # Creating a z-dimension with size 1 for consistency.\n",
    "        output_dataset.createDimension('y', num_y) \n",
    "        output_dataset.createDimension('x', num_x) \n",
    "        \n",
    "        # Also copy coordinate variables if they exist and are useful\n",
    "        if 'time' in current_dataset.variables:\n",
    "            time_var = output_dataset.createVariable('time', current_dataset['time'].dtype, ('time',))\n",
    "            time_var[:] = current_dataset['time'][time_lists[0][0]:time_lists[-1][-1]+1:aggregate_time_steps] # Simplified time assignment.\n",
    "            # This assumes time steps are regular. A more precise way would be to average time, or pick central time.\n",
    "            # For this context, picking the start of the first window to the end of the last window at aggregation interval.\n",
    "        if 'z' in current_dataset.variables:\n",
    "            z_var = output_dataset.createVariable('z', current_dataset['z'].dtype, ('z',))\n",
    "            z_var[:] = current_dataset['z'][0] # Copy the z-coordinate of the extracted layer.\n",
    "        if 'y' in current_dataset.variables:\n",
    "            y_var = output_dataset.createVariable('y', current_dataset['y'].dtype, ('y',))\n",
    "            y_var[:] = current_dataset['y'][:]\n",
    "        if 'x' in current_dataset.variables:\n",
    "            x_var = output_dataset.createVariable('x', current_dataset['x'].dtype, ('x',))\n",
    "            x_var[:] = current_dataset['x'][:]\n",
    "\n",
    "\n",
    "        # Create the variable in the new NetCDF file.\n",
    "        # The dimensions are (time, z, y, x) to maintain a consistent structure with PALM 4D outputs.\n",
    "        data_var = output_dataset.createVariable(f'{test_variable}', np.float32, ('time', 'z', 'y', 'x'), \n",
    "                                               fill_value=variable_data._FillValue if '_FillValue' in variable_data.ncattrs() else -9999.0) # Copy fill value\n",
    "\n",
    "        # Fill the newly created variable with the aggregated 2D data.\n",
    "        # Each aggregated 2D array is assigned to its corresponding time step and the first z-layer.\n",
    "        for k, array in enumerate(variable_data_agg):\n",
    "            data_var[k, 0, :, :] = array # Assign the 2D aggregated array to the NetCDF variable\n",
    "\n",
    "    print(f\"Successfully extracted and saved aggregated data for '{test_variable}' to: {output_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coklimax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
